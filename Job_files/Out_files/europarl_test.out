2022-07-12 11:52:16 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/RoBERTa_10_finetune.pt
2022-07-12 11:52:17 | INFO | fairseq.tasks.masked_lm | dictionary: 39984 types
2022-07-12 11:52:27 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'RoBERTa', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/RoBERTa_10_finetune.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15262', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/dahmanir/lisa/Models/RoBERTa_10.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_dropout': 0.0, 'pooler_dropout': 0.0, 'max_source_positions': 512, 'no_token_positional_embeddings': False, 'encoder_learned_pos': True, 'layernorm_embedding': True, 'no_scale_embedding': True, 'activation_fn': 'gelu', 'encoder_normalize_before': False, 'pooler_activation_fn': 'tanh', 'untie_weights_roberta': False, 'adaptive_input': False, 'encoder_layerdrop': 0.0, 'encoder_layers_to_keep': None, 'quant_noise_pq': 0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0, 'spectral_norm_classification_head': False}, 'task': {'_name': 'masked_lm', 'data': 'lisa/Datasets/europarl_nl_bin', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
2022-07-12 11:52:27 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 11:52:28 | INFO | fairseq.tasks.masked_lm | loaded 127997 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 11:52:28 | WARNING | fairseq.tasks.fairseq_task | 16 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[91279, 98239, 123892, 104545, 120813, 113078, 106642, 109767, 110720, 105213]
2022-07-12 11:52:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 15998 loss=998.0558471679688, ntokens=3392, nsentences=8, sample_size=510
2022-07-12 11:52:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 15998 loss=1007.4767456054688, ntokens=3496, nsentences=8, sample_size=524
2022-07-12 11:53:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 15998 loss=1044.364501953125, ntokens=3544, nsentences=8, sample_size=531
2022-07-12 11:53:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 15998 loss=941.578857421875, ntokens=3584, nsentences=8, sample_size=538
2022-07-12 11:53:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 15998 loss=1001.726318359375, ntokens=3608, nsentences=8, sample_size=543
2022-07-12 11:53:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 15998 loss=1075.3485107421875, ntokens=3632, nsentences=8, sample_size=544
2022-07-12 11:53:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 15998 loss=1107.239013671875, ntokens=3648, nsentences=8, sample_size=546
2022-07-12 11:54:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 15998 loss=1020.7393188476562, ntokens=3664, nsentences=8, sample_size=550
2022-07-12 11:54:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 15998 loss=1024.723388671875, ntokens=3680, nsentences=8, sample_size=552
2022-07-12 11:54:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 15998 loss=904.1265258789062, ntokens=3696, nsentences=8, sample_size=556
2022-07-12 11:54:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 15998 loss=978.8637084960938, ntokens=3704, nsentences=8, sample_size=557
2022-07-12 11:54:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 15998 loss=1065.6761474609375, ntokens=3720, nsentences=8, sample_size=559
2022-07-12 11:55:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 15998 loss=1055.5869140625, ntokens=3728, nsentences=8, sample_size=559
2022-07-12 11:55:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 15998 loss=970.1679077148438, ntokens=3736, nsentences=8, sample_size=560
2022-07-12 11:55:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 15998 loss=1024.7076416015625, ntokens=3744, nsentences=8, sample_size=560
2022-07-12 11:55:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 15998 loss=1165.3338623046875, ntokens=3752, nsentences=8, sample_size=565
2022-07-12 11:55:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 15998 loss=1076.4158935546875, ntokens=3760, nsentences=8, sample_size=565
2022-07-12 11:56:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 15998 loss=1170.5396728515625, ntokens=3768, nsentences=8, sample_size=566
2022-07-12 11:56:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 15998 loss=1080.790771484375, ntokens=3768, nsentences=8, sample_size=565
2022-07-12 11:56:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 15998 loss=1124.3834228515625, ntokens=3776, nsentences=8, sample_size=567
2022-07-12 11:56:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 15998 loss=1076.9208984375, ntokens=3784, nsentences=8, sample_size=568
2022-07-12 11:56:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 15998 loss=1208.714599609375, ntokens=3792, nsentences=8, sample_size=570
2022-07-12 11:57:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 15998 loss=1286.7115478515625, ntokens=3792, nsentences=8, sample_size=568
2022-07-12 11:57:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 15998 loss=1112.80712890625, ntokens=3800, nsentences=8, sample_size=571
2022-07-12 11:57:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 15998 loss=1031.97314453125, ntokens=3808, nsentences=8, sample_size=569
2022-07-12 11:57:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 15998 loss=1134.1549072265625, ntokens=3808, nsentences=8, sample_size=570
2022-07-12 11:58:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 15998 loss=1163.6666259765625, ntokens=3816, nsentences=8, sample_size=574
2022-07-12 11:58:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 15998 loss=1032.7606201171875, ntokens=3816, nsentences=8, sample_size=572
2022-07-12 11:58:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 15998 loss=1063.662353515625, ntokens=3824, nsentences=8, sample_size=575
2022-07-12 11:58:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 15998 loss=1128.4849853515625, ntokens=3832, nsentences=8, sample_size=573
2022-07-12 11:58:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 15998 loss=1228.619873046875, ntokens=3832, nsentences=8, sample_size=575
2022-07-12 11:59:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 15998 loss=1095.537353515625, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 11:59:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 15998 loss=983.8635864257812, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 11:59:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 15998 loss=1155.9915771484375, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 11:59:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 15998 loss=923.1263427734375, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 11:59:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 15998 loss=1090.4288330078125, ntokens=3848, nsentences=8, sample_size=577
2022-07-12 12:00:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 15998 loss=1019.1442260742188, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 12:00:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 15998 loss=963.1202392578125, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 12:00:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 15998 loss=1108.55859375, ntokens=3864, nsentences=8, sample_size=580
2022-07-12 12:00:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 15998 loss=1047.5245361328125, ntokens=3864, nsentences=8, sample_size=581
2022-07-12 12:01:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 15998 loss=1061.7635498046875, ntokens=3872, nsentences=8, sample_size=581
2022-07-12 12:01:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 15998 loss=1055.6639404296875, ntokens=3872, nsentences=8, sample_size=583
2022-07-12 12:01:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 15998 loss=1205.8748779296875, ntokens=3872, nsentences=8, sample_size=582
2022-07-12 12:01:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 15998 loss=1168.7236328125, ntokens=3880, nsentences=8, sample_size=582
2022-07-12 12:01:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 15998 loss=1124.8934326171875, ntokens=3880, nsentences=8, sample_size=580
2022-07-12 12:02:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 15998 loss=1065.681884765625, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 12:02:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 15998 loss=1203.06298828125, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 12:02:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 15998 loss=1096.793701171875, ntokens=3888, nsentences=8, sample_size=582
2022-07-12 12:02:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 15998 loss=1088.6434326171875, ntokens=3896, nsentences=8, sample_size=584
2022-07-12 12:03:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 15998 loss=1133.2886962890625, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 12:03:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 15998 loss=1139.6778564453125, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 12:03:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 15998 loss=1239.7589111328125, ntokens=3904, nsentences=8, sample_size=587
2022-07-12 12:03:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 15998 loss=1230.783447265625, ntokens=3904, nsentences=8, sample_size=585
2022-07-12 12:04:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 15998 loss=1226.0706787109375, ntokens=3904, nsentences=8, sample_size=584
2022-07-12 12:04:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 15998 loss=1176.8419189453125, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 12:04:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 15998 loss=1105.0306396484375, ntokens=3912, nsentences=8, sample_size=584
2022-07-12 12:04:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 15998 loss=1095.971923828125, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 12:04:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 15998 loss=1120.13720703125, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 12:05:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 15998 loss=1076.32470703125, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 12:05:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 15998 loss=921.8018798828125, ntokens=3920, nsentences=8, sample_size=587
2022-07-12 12:05:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 15998 loss=1040.80810546875, ntokens=3928, nsentences=8, sample_size=590
2022-07-12 12:05:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 15998 loss=1161.4183349609375, ntokens=3928, nsentences=8, sample_size=591
2022-07-12 12:06:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 15998 loss=1069.4329833984375, ntokens=3928, nsentences=8, sample_size=589
2022-07-12 12:06:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 15998 loss=1187.0604248046875, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 12:06:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 15998 loss=1278.2213134765625, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 12:06:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 15998 loss=1015.7308349609375, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 12:06:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 15998 loss=1153.401611328125, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 12:07:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 15998 loss=1166.46142578125, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 12:07:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 15998 loss=1311.110595703125, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 12:07:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 15998 loss=1188.72607421875, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 12:07:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 15998 loss=1120.5035400390625, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 12:08:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 15998 loss=1228.50439453125, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 12:08:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 15998 loss=1093.0343017578125, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 12:08:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 15998 loss=1232.589111328125, ntokens=3952, nsentences=8, sample_size=595
2022-07-12 12:08:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 15998 loss=991.3792724609375, ntokens=3960, nsentences=8, sample_size=592
2022-07-12 12:08:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 15998 loss=1202.410400390625, ntokens=3960, nsentences=8, sample_size=594
2022-07-12 12:09:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 15998 loss=1093.796875, ntokens=3960, nsentences=8, sample_size=595
2022-07-12 12:09:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 15998 loss=1092.3165283203125, ntokens=3960, nsentences=8, sample_size=596
2022-07-12 12:09:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 15998 loss=1205.450439453125, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 12:09:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 15998 loss=1044.8594970703125, ntokens=3968, nsentences=8, sample_size=593
2022-07-12 12:10:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 15998 loss=1080.061279296875, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 12:10:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 15998 loss=1265.753662109375, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 12:10:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 15998 loss=1160.6478271484375, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 12:10:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 15998 loss=1104.6356201171875, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 12:11:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 15998 loss=995.2372436523438, ntokens=3976, nsentences=8, sample_size=599
2022-07-12 12:11:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 15998 loss=1194.3341064453125, ntokens=3976, nsentences=8, sample_size=597
2022-07-12 12:11:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 15998 loss=1116.7535400390625, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 12:11:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 15998 loss=1032.2469482421875, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 12:11:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 15998 loss=1001.8635864257812, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 12:12:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 15998 loss=1179.4019775390625, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 12:12:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 15998 loss=1047.3165283203125, ntokens=3984, nsentences=8, sample_size=599
2022-07-12 12:12:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 15998 loss=1256.653076171875, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 12:12:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 15998 loss=1090.8790283203125, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 12:12:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 15998 loss=1129.3004150390625, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 12:13:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 15998 loss=1248.6312255859375, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 12:13:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 15998 loss=1147.113525390625, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 12:13:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 15998 loss=1239.1502685546875, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:13:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 15998 loss=1255.009765625, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:14:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 15998 loss=1252.5775146484375, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:14:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 15998 loss=1182.75244140625, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:14:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 15998 loss=1239.0625, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 12:14:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 15998 loss=1084.4815673828125, ntokens=4008, nsentences=8, sample_size=602
2022-07-12 12:14:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 15998 loss=1007.4647216796875, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 12:15:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 15998 loss=1010.06494140625, ntokens=4008, nsentences=8, sample_size=600
2022-07-12 12:15:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 15998 loss=1067.658447265625, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 12:15:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 15998 loss=1116.3323974609375, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 12:15:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 15998 loss=1101.5648193359375, ntokens=4016, nsentences=8, sample_size=606
2022-07-12 12:16:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 15998 loss=1086.9639892578125, ntokens=4016, nsentences=8, sample_size=605
2022-07-12 12:16:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 15998 loss=1226.5565185546875, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 12:16:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 15998 loss=1126.0701904296875, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 12:16:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 15998 loss=1112.3170166015625, ntokens=4024, nsentences=8, sample_size=605
2022-07-12 12:16:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 15998 loss=1182.9688720703125, ntokens=4024, nsentences=8, sample_size=606
2022-07-12 12:17:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 15998 loss=1129.0921630859375, ntokens=4024, nsentences=8, sample_size=603
2022-07-12 12:17:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 15998 loss=1098.021728515625, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 12:17:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 15998 loss=1209.3450927734375, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 12:17:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 15998 loss=1172.3323974609375, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 12:18:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 15998 loss=1231.0509033203125, ntokens=4032, nsentences=8, sample_size=605
2022-07-12 12:18:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 15998 loss=1112.3350830078125, ntokens=4032, nsentences=8, sample_size=601
2022-07-12 12:18:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 15998 loss=1233.9278564453125, ntokens=4032, nsentences=8, sample_size=607
2022-07-12 12:18:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 15998 loss=1153.7176513671875, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 12:18:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 15998 loss=1161.5037841796875, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 12:19:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 15998 loss=1161.994873046875, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 12:19:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 15998 loss=1099.1922607421875, ntokens=4040, nsentences=8, sample_size=607
2022-07-12 12:19:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 15998 loss=1230.66943359375, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 12:19:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 15998 loss=1079.4134521484375, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 12:20:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 15998 loss=1115.967041015625, ntokens=4048, nsentences=8, sample_size=608
2022-07-12 12:20:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 15998 loss=1151.8857421875, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 12:20:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 15998 loss=988.4630126953125, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 12:20:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 15998 loss=1099.5162353515625, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 12:20:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 15998 loss=1061.8802490234375, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 12:21:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 15998 loss=1251.0697021484375, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 12:21:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 15998 loss=1163.6580810546875, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 12:21:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 15998 loss=1082.54736328125, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 12:21:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 15998 loss=1143.2679443359375, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 12:22:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 15998 loss=1315.7095947265625, ntokens=4064, nsentences=8, sample_size=609
2022-07-12 12:22:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 15998 loss=1102.6702880859375, ntokens=4064, nsentences=8, sample_size=608
2022-07-12 12:22:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 15998 loss=1211.5186767578125, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 12:22:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 15998 loss=1145.6700439453125, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 12:22:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 15998 loss=1093.342041015625, ntokens=4064, nsentences=8, sample_size=612
2022-07-12 12:23:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 15998 loss=1120.29052734375, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 12:23:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 15998 loss=1219.486328125, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 12:23:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 15998 loss=1221.2288818359375, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 12:23:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 15998 loss=1183.464599609375, ntokens=4072, nsentences=8, sample_size=608
2022-07-12 12:24:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 15998 loss=1219.297119140625, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 12:24:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 15998 loss=1054.863525390625, ntokens=4080, nsentences=8, sample_size=613
2022-07-12 12:24:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 15998 loss=1158.1695556640625, ntokens=4080, nsentences=8, sample_size=614
2022-07-12 12:24:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 15998 loss=1192.3375244140625, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 12:24:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 15998 loss=1211.3740234375, ntokens=4080, nsentences=8, sample_size=611
2022-07-12 12:25:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 15998 loss=1327.77197265625, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 12:25:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 15998 loss=1181.7822265625, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 12:25:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 15998 loss=1202.074951171875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 12:25:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 15998 loss=1129.6170654296875, ntokens=4088, nsentences=8, sample_size=614
2022-07-12 12:26:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 15998 loss=1203.75439453125, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 12:26:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 15998 loss=1117.5797119140625, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 12:26:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 15998 loss=1133.5302734375, ntokens=4096, nsentences=8, sample_size=613
2022-07-12 12:26:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 15998 loss=1377.0665283203125, ntokens=4096, nsentences=8, sample_size=612
2022-07-12 12:26:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 15998 loss=1035.2601318359375, ntokens=4096, nsentences=8, sample_size=614
2022-07-12 12:27:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 15998 loss=1271.585205078125, ntokens=4096, nsentences=8, sample_size=616
2022-07-12 12:27:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 15998 loss=1176.78125, ntokens=4096, nsentences=8, sample_size=615
2022-07-12 12:27:32 | INFO | valid | valid on 'valid' subset | loss 2.744 | ppl 6.7 | wps 0 | wpb 6.2902e+07 | bsz 127981
2022-07-12 12:27:39 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/RoBERTa_25_finetune.pt
2022-07-12 12:27:40 | INFO | fairseq.tasks.masked_lm | dictionary: 39984 types
2022-07-12 12:27:52 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'RoBERTa', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/RoBERTa_25_finetune.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15810', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 4, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/dahmanir/lisa/Models/RoBERTa_25.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_dropout': 0.0, 'pooler_dropout': 0.0, 'max_source_positions': 512, 'no_token_positional_embeddings': False, 'encoder_learned_pos': True, 'layernorm_embedding': True, 'no_scale_embedding': True, 'activation_fn': 'gelu', 'encoder_normalize_before': False, 'pooler_activation_fn': 'tanh', 'untie_weights_roberta': False, 'adaptive_input': False, 'encoder_layerdrop': 0.0, 'encoder_layers_to_keep': None, 'quant_noise_pq': 0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0, 'spectral_norm_classification_head': False}, 'task': {'_name': 'masked_lm', 'data': 'lisa/Datasets/europarl_nl_bin', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
2022-07-12 12:27:52 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 12:27:52 | INFO | fairseq.tasks.masked_lm | loaded 127997 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 12:27:52 | WARNING | fairseq.tasks.fairseq_task | 16 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[91279, 98239, 123892, 104545, 120813, 113078, 106642, 109767, 110720, 105213]
2022-07-12 12:28:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 15998 loss=988.7001342773438, ntokens=3392, nsentences=8, sample_size=510
2022-07-12 12:28:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 15998 loss=999.0963745117188, ntokens=3496, nsentences=8, sample_size=524
2022-07-12 12:28:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 15998 loss=1031.451904296875, ntokens=3544, nsentences=8, sample_size=531
2022-07-12 12:28:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 15998 loss=938.7098999023438, ntokens=3584, nsentences=8, sample_size=538
2022-07-12 12:28:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 15998 loss=1010.8604125976562, ntokens=3608, nsentences=8, sample_size=543
2022-07-12 12:29:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 15998 loss=1090.22900390625, ntokens=3632, nsentences=8, sample_size=544
2022-07-12 12:29:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 15998 loss=1094.2349853515625, ntokens=3648, nsentences=8, sample_size=546
2022-07-12 12:29:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 15998 loss=1004.6033935546875, ntokens=3664, nsentences=8, sample_size=550
2022-07-12 12:29:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 15998 loss=1024.68310546875, ntokens=3680, nsentences=8, sample_size=552
2022-07-12 12:29:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 15998 loss=886.968505859375, ntokens=3696, nsentences=8, sample_size=556
2022-07-12 12:30:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 15998 loss=973.8184814453125, ntokens=3704, nsentences=8, sample_size=557
2022-07-12 12:30:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 15998 loss=1061.7222900390625, ntokens=3720, nsentences=8, sample_size=559
2022-07-12 12:30:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 15998 loss=1047.1903076171875, ntokens=3728, nsentences=8, sample_size=559
2022-07-12 12:30:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 15998 loss=958.7568359375, ntokens=3736, nsentences=8, sample_size=560
2022-07-12 12:30:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 15998 loss=1019.42529296875, ntokens=3744, nsentences=8, sample_size=560
2022-07-12 12:31:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 15998 loss=1158.0499267578125, ntokens=3752, nsentences=8, sample_size=565
2022-07-12 12:31:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 15998 loss=1062.1290283203125, ntokens=3760, nsentences=8, sample_size=565
2022-07-12 12:31:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 15998 loss=1149.4432373046875, ntokens=3768, nsentences=8, sample_size=566
2022-07-12 12:31:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 15998 loss=1075.7950439453125, ntokens=3768, nsentences=8, sample_size=565
2022-07-12 12:31:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 15998 loss=1120.4359130859375, ntokens=3776, nsentences=8, sample_size=567
2022-07-12 12:32:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 15998 loss=1055.9873046875, ntokens=3784, nsentences=8, sample_size=568
2022-07-12 12:32:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 15998 loss=1203.020263671875, ntokens=3792, nsentences=8, sample_size=570
2022-07-12 12:32:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 15998 loss=1274.51806640625, ntokens=3792, nsentences=8, sample_size=568
2022-07-12 12:32:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 15998 loss=1105.5242919921875, ntokens=3800, nsentences=8, sample_size=571
2022-07-12 12:32:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 15998 loss=1031.0255126953125, ntokens=3808, nsentences=8, sample_size=569
2022-07-12 12:33:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 15998 loss=1149.75146484375, ntokens=3808, nsentences=8, sample_size=570
2022-07-12 12:33:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 15998 loss=1153.1478271484375, ntokens=3816, nsentences=8, sample_size=574
2022-07-12 12:33:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 15998 loss=1028.564453125, ntokens=3816, nsentences=8, sample_size=572
2022-07-12 12:33:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 15998 loss=1059.330322265625, ntokens=3824, nsentences=8, sample_size=575
2022-07-12 12:34:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 15998 loss=1101.8114013671875, ntokens=3832, nsentences=8, sample_size=573
2022-07-12 12:34:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 15998 loss=1221.6075439453125, ntokens=3832, nsentences=8, sample_size=575
2022-07-12 12:34:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 15998 loss=1097.2840576171875, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 12:34:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 15998 loss=969.4567260742188, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 12:34:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 15998 loss=1142.9437255859375, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 12:35:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 15998 loss=932.10986328125, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 12:35:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 15998 loss=1064.578369140625, ntokens=3848, nsentences=8, sample_size=577
2022-07-12 12:35:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 15998 loss=1025.723388671875, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 12:35:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 15998 loss=964.00927734375, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 12:36:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 15998 loss=1102.81787109375, ntokens=3864, nsentences=8, sample_size=580
2022-07-12 12:36:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 15998 loss=1037.802734375, ntokens=3864, nsentences=8, sample_size=581
2022-07-12 12:36:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 15998 loss=1049.8568115234375, ntokens=3872, nsentences=8, sample_size=581
2022-07-12 12:36:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 15998 loss=1061.5604248046875, ntokens=3872, nsentences=8, sample_size=583
2022-07-12 12:36:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 15998 loss=1213.4998779296875, ntokens=3872, nsentences=8, sample_size=582
2022-07-12 12:37:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 15998 loss=1164.7044677734375, ntokens=3880, nsentences=8, sample_size=582
2022-07-12 12:37:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 15998 loss=1113.77392578125, ntokens=3880, nsentences=8, sample_size=580
2022-07-12 12:37:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 15998 loss=1070.0118408203125, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 12:37:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 15998 loss=1190.9971923828125, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 12:38:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 15998 loss=1078.9168701171875, ntokens=3888, nsentences=8, sample_size=582
2022-07-12 12:38:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 15998 loss=1079.4967041015625, ntokens=3896, nsentences=8, sample_size=584
2022-07-12 12:38:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 15998 loss=1118.8553466796875, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 12:38:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 15998 loss=1134.556640625, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 12:38:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 15998 loss=1235.8668212890625, ntokens=3904, nsentences=8, sample_size=587
2022-07-12 12:39:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 15998 loss=1221.4039306640625, ntokens=3904, nsentences=8, sample_size=585
2022-07-12 12:39:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 15998 loss=1209.658935546875, ntokens=3904, nsentences=8, sample_size=584
2022-07-12 12:39:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 15998 loss=1169.2939453125, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 12:39:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 15998 loss=1100.065185546875, ntokens=3912, nsentences=8, sample_size=584
2022-07-12 12:40:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 15998 loss=1099.635498046875, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 12:40:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 15998 loss=1120.094482421875, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 12:40:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 15998 loss=1088.3575439453125, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 12:40:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 15998 loss=922.8877563476562, ntokens=3920, nsentences=8, sample_size=587
2022-07-12 12:41:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 15998 loss=1028.158447265625, ntokens=3928, nsentences=8, sample_size=590
2022-07-12 12:41:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 15998 loss=1151.9208984375, ntokens=3928, nsentences=8, sample_size=591
2022-07-12 12:41:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 15998 loss=1078.2177734375, ntokens=3928, nsentences=8, sample_size=589
2022-07-12 12:41:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 15998 loss=1188.021240234375, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 12:41:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 15998 loss=1256.43359375, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 12:42:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 15998 loss=1011.20361328125, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 12:42:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 15998 loss=1142.0286865234375, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 12:42:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 15998 loss=1153.9505615234375, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 12:42:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 15998 loss=1297.7626953125, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 12:43:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 15998 loss=1188.377197265625, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 12:43:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 15998 loss=1113.1407470703125, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 12:43:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 15998 loss=1226.4178466796875, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 12:43:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 15998 loss=1099.75537109375, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 12:43:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 15998 loss=1240.03125, ntokens=3952, nsentences=8, sample_size=595
2022-07-12 12:44:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 15998 loss=974.750732421875, ntokens=3960, nsentences=8, sample_size=592
2022-07-12 12:44:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 15998 loss=1207.0577392578125, ntokens=3960, nsentences=8, sample_size=594
2022-07-12 12:44:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 15998 loss=1079.9637451171875, ntokens=3960, nsentences=8, sample_size=595
2022-07-12 12:44:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 15998 loss=1096.5887451171875, ntokens=3960, nsentences=8, sample_size=596
2022-07-12 12:45:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 15998 loss=1208.3682861328125, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 12:45:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 15998 loss=1045.8958740234375, ntokens=3968, nsentences=8, sample_size=593
2022-07-12 12:45:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 15998 loss=1077.814208984375, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 12:45:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 15998 loss=1262.4066162109375, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 12:45:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 15998 loss=1156.29931640625, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 12:46:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 15998 loss=1104.6173095703125, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 12:46:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 15998 loss=981.374267578125, ntokens=3976, nsentences=8, sample_size=599
2022-07-12 12:46:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 15998 loss=1190.0479736328125, ntokens=3976, nsentences=8, sample_size=597
2022-07-12 12:46:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 15998 loss=1125.2640380859375, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 12:47:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 15998 loss=1026.1719970703125, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 12:47:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 15998 loss=995.2255249023438, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 12:47:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 15998 loss=1167.05078125, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 12:47:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 15998 loss=1047.8375244140625, ntokens=3984, nsentences=8, sample_size=599
2022-07-12 12:47:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 15998 loss=1231.434814453125, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 12:48:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 15998 loss=1085.0142822265625, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 12:48:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 15998 loss=1146.781982421875, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 12:48:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 15998 loss=1242.4097900390625, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 12:48:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 15998 loss=1129.879638671875, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 12:49:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 15998 loss=1232.4034423828125, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:49:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 15998 loss=1235.098876953125, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:49:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 15998 loss=1252.904541015625, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:49:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 15998 loss=1163.89794921875, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 12:49:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 15998 loss=1236.18408203125, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 12:50:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 15998 loss=1100.5462646484375, ntokens=4008, nsentences=8, sample_size=602
2022-07-12 12:50:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 15998 loss=1011.9197387695312, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 12:50:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 15998 loss=1010.3155517578125, ntokens=4008, nsentences=8, sample_size=600
2022-07-12 12:50:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 15998 loss=1056.4716796875, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 12:51:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 15998 loss=1112.6556396484375, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 12:51:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 15998 loss=1097.43212890625, ntokens=4016, nsentences=8, sample_size=606
2022-07-12 12:51:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 15998 loss=1079.97412109375, ntokens=4016, nsentences=8, sample_size=605
2022-07-12 12:51:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 15998 loss=1230.731689453125, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 12:51:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 15998 loss=1115.6641845703125, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 12:52:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 15998 loss=1109.2109375, ntokens=4024, nsentences=8, sample_size=605
2022-07-12 12:52:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 15998 loss=1177.3814697265625, ntokens=4024, nsentences=8, sample_size=606
2022-07-12 12:52:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 15998 loss=1137.762451171875, ntokens=4024, nsentences=8, sample_size=603
2022-07-12 12:52:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 15998 loss=1091.9163818359375, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 12:53:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 15998 loss=1190.5306396484375, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 12:53:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 15998 loss=1188.33544921875, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 12:53:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 15998 loss=1239.9947509765625, ntokens=4032, nsentences=8, sample_size=605
2022-07-12 12:53:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 15998 loss=1111.203369140625, ntokens=4032, nsentences=8, sample_size=601
2022-07-12 12:53:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 15998 loss=1246.23828125, ntokens=4032, nsentences=8, sample_size=607
2022-07-12 12:54:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 15998 loss=1139.5406494140625, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 12:54:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 15998 loss=1152.4595947265625, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 12:54:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 15998 loss=1164.7579345703125, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 12:54:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 15998 loss=1096.061767578125, ntokens=4040, nsentences=8, sample_size=607
2022-07-12 12:55:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 15998 loss=1239.301513671875, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 12:55:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 15998 loss=1083.838134765625, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 12:55:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 15998 loss=1117.3687744140625, ntokens=4048, nsentences=8, sample_size=608
2022-07-12 12:55:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 15998 loss=1146.5186767578125, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 12:55:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 15998 loss=995.8260498046875, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 12:56:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 15998 loss=1105.8734130859375, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 12:56:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 15998 loss=1066.667236328125, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 12:56:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 15998 loss=1242.267578125, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 12:56:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 15998 loss=1160.199951171875, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 12:57:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 15998 loss=1083.1292724609375, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 12:57:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 15998 loss=1148.602294921875, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 12:57:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 15998 loss=1297.1260986328125, ntokens=4064, nsentences=8, sample_size=609
2022-07-12 12:57:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 15998 loss=1110.822265625, ntokens=4064, nsentences=8, sample_size=608
2022-07-12 12:57:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 15998 loss=1192.1708984375, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 12:58:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 15998 loss=1134.1968994140625, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 12:58:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 15998 loss=1085.4595947265625, ntokens=4064, nsentences=8, sample_size=612
2022-07-12 12:58:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 15998 loss=1132.2530517578125, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 12:58:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 15998 loss=1207.8814697265625, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 12:58:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 15998 loss=1213.6185302734375, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 12:59:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 15998 loss=1171.5213623046875, ntokens=4072, nsentences=8, sample_size=608
2022-07-12 12:59:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 15998 loss=1224.2857666015625, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 12:59:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 15998 loss=1055.3720703125, ntokens=4080, nsentences=8, sample_size=613
2022-07-12 12:59:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 15998 loss=1168.3135986328125, ntokens=4080, nsentences=8, sample_size=614
2022-07-12 13:00:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 15998 loss=1191.5738525390625, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 13:00:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 15998 loss=1199.81591796875, ntokens=4080, nsentences=8, sample_size=611
2022-07-12 13:00:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 15998 loss=1312.269287109375, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 13:00:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 15998 loss=1178.93310546875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:00:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 15998 loss=1189.4847412109375, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:01:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 15998 loss=1133.7574462890625, ntokens=4088, nsentences=8, sample_size=614
2022-07-12 13:01:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 15998 loss=1193.6121826171875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:01:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 15998 loss=1122.895263671875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:01:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 15998 loss=1110.9656982421875, ntokens=4096, nsentences=8, sample_size=613
2022-07-12 13:02:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 15998 loss=1367.7794189453125, ntokens=4096, nsentences=8, sample_size=612
2022-07-12 13:02:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 15998 loss=1020.0537109375, ntokens=4096, nsentences=8, sample_size=614
2022-07-12 13:02:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 15998 loss=1254.5047607421875, ntokens=4096, nsentences=8, sample_size=616
2022-07-12 13:02:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 15998 loss=1167.8011474609375, ntokens=4096, nsentences=8, sample_size=615
2022-07-12 13:02:56 | INFO | valid | valid on 'valid' subset | loss 2.735 | ppl 6.66 | wps 0 | wpb 6.2902e+07 | bsz 127981
2022-07-12 13:03:02 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/RoBERTa_50_finetune.pt
2022-07-12 13:03:03 | INFO | fairseq.tasks.masked_lm | dictionary: 39984 types
2022-07-12 13:03:15 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'RoBERTa', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/RoBERTa_50_finetune.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14344', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/dahmanir/lisa/Models/RoBERTa_50.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_dropout': 0.0, 'pooler_dropout': 0.0, 'max_source_positions': 512, 'no_token_positional_embeddings': False, 'encoder_learned_pos': True, 'layernorm_embedding': True, 'no_scale_embedding': True, 'activation_fn': 'gelu', 'encoder_normalize_before': False, 'pooler_activation_fn': 'tanh', 'untie_weights_roberta': False, 'adaptive_input': False, 'encoder_layerdrop': 0.0, 'encoder_layers_to_keep': None, 'quant_noise_pq': 0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0, 'spectral_norm_classification_head': False}, 'task': {'_name': 'masked_lm', 'data': 'lisa/Datasets/europarl_nl_bin', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
2022-07-12 13:03:15 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 13:03:16 | INFO | fairseq.tasks.masked_lm | loaded 127997 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 13:03:16 | WARNING | fairseq.tasks.fairseq_task | 16 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[91279, 98239, 123892, 104545, 120813, 113078, 106642, 109767, 110720, 105213]
2022-07-12 13:03:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 15998 loss=994.7402954101562, ntokens=3392, nsentences=8, sample_size=510
2022-07-12 13:03:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 15998 loss=999.6216430664062, ntokens=3496, nsentences=8, sample_size=524
2022-07-12 13:03:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 15998 loss=1022.0076904296875, ntokens=3544, nsentences=8, sample_size=531
2022-07-12 13:04:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 15998 loss=943.4027099609375, ntokens=3584, nsentences=8, sample_size=538
2022-07-12 13:04:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 15998 loss=1007.7371826171875, ntokens=3608, nsentences=8, sample_size=543
2022-07-12 13:04:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 15998 loss=1088.7957763671875, ntokens=3632, nsentences=8, sample_size=544
2022-07-12 13:04:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 15998 loss=1120.56787109375, ntokens=3648, nsentences=8, sample_size=546
2022-07-12 13:04:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 15998 loss=1010.7141723632812, ntokens=3664, nsentences=8, sample_size=550
2022-07-12 13:05:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 15998 loss=1012.0950317382812, ntokens=3680, nsentences=8, sample_size=552
2022-07-12 13:05:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 15998 loss=892.245361328125, ntokens=3696, nsentences=8, sample_size=556
2022-07-12 13:05:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 15998 loss=968.2642211914062, ntokens=3704, nsentences=8, sample_size=557
2022-07-12 13:05:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 15998 loss=1060.2667236328125, ntokens=3720, nsentences=8, sample_size=559
2022-07-12 13:05:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 15998 loss=1038.4281005859375, ntokens=3728, nsentences=8, sample_size=559
2022-07-12 13:06:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 15998 loss=951.3023681640625, ntokens=3736, nsentences=8, sample_size=560
2022-07-12 13:06:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 15998 loss=1011.0092163085938, ntokens=3744, nsentences=8, sample_size=560
2022-07-12 13:06:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 15998 loss=1164.5572509765625, ntokens=3752, nsentences=8, sample_size=565
2022-07-12 13:06:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 15998 loss=1070.20263671875, ntokens=3760, nsentences=8, sample_size=565
2022-07-12 13:06:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 15998 loss=1167.597412109375, ntokens=3768, nsentences=8, sample_size=566
2022-07-12 13:07:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 15998 loss=1071.1217041015625, ntokens=3768, nsentences=8, sample_size=565
2022-07-12 13:07:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 15998 loss=1118.5084228515625, ntokens=3776, nsentences=8, sample_size=567
2022-07-12 13:07:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 15998 loss=1073.9302978515625, ntokens=3784, nsentences=8, sample_size=568
2022-07-12 13:07:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 15998 loss=1201.0601806640625, ntokens=3792, nsentences=8, sample_size=570
2022-07-12 13:07:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 15998 loss=1265.5277099609375, ntokens=3792, nsentences=8, sample_size=568
2022-07-12 13:08:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 15998 loss=1097.1055908203125, ntokens=3800, nsentences=8, sample_size=571
2022-07-12 13:08:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 15998 loss=1021.904541015625, ntokens=3808, nsentences=8, sample_size=569
2022-07-12 13:08:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 15998 loss=1128.4647216796875, ntokens=3808, nsentences=8, sample_size=570
2022-07-12 13:08:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 15998 loss=1151.1146240234375, ntokens=3816, nsentences=8, sample_size=574
2022-07-12 13:09:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 15998 loss=1028.0257568359375, ntokens=3816, nsentences=8, sample_size=572
2022-07-12 13:09:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 15998 loss=1050.4892578125, ntokens=3824, nsentences=8, sample_size=575
2022-07-12 13:09:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 15998 loss=1098.3377685546875, ntokens=3832, nsentences=8, sample_size=573
2022-07-12 13:09:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 15998 loss=1227.409912109375, ntokens=3832, nsentences=8, sample_size=575
2022-07-12 13:09:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 15998 loss=1096.93017578125, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 13:10:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 15998 loss=988.7181396484375, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 13:10:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 15998 loss=1147.738525390625, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 13:10:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 15998 loss=934.615234375, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 13:10:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 15998 loss=1071.8514404296875, ntokens=3848, nsentences=8, sample_size=577
2022-07-12 13:11:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 15998 loss=1016.695556640625, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 13:11:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 15998 loss=958.787353515625, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 13:11:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 15998 loss=1108.61767578125, ntokens=3864, nsentences=8, sample_size=580
2022-07-12 13:11:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 15998 loss=1043.321533203125, ntokens=3864, nsentences=8, sample_size=581
2022-07-12 13:11:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 15998 loss=1051.595458984375, ntokens=3872, nsentences=8, sample_size=581
2022-07-12 13:12:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 15998 loss=1065.6329345703125, ntokens=3872, nsentences=8, sample_size=583
2022-07-12 13:12:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 15998 loss=1196.29443359375, ntokens=3872, nsentences=8, sample_size=582
2022-07-12 13:12:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 15998 loss=1165.34033203125, ntokens=3880, nsentences=8, sample_size=582
2022-07-12 13:12:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 15998 loss=1112.40576171875, ntokens=3880, nsentences=8, sample_size=580
2022-07-12 13:13:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 15998 loss=1059.4033203125, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 13:13:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 15998 loss=1190.1114501953125, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 13:13:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 15998 loss=1086.0155029296875, ntokens=3888, nsentences=8, sample_size=582
2022-07-12 13:13:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 15998 loss=1086.203369140625, ntokens=3896, nsentences=8, sample_size=584
2022-07-12 13:13:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 15998 loss=1119.55224609375, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 13:14:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 15998 loss=1127.0257568359375, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 13:14:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 15998 loss=1220.098388671875, ntokens=3904, nsentences=8, sample_size=587
2022-07-12 13:14:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 15998 loss=1232.07568359375, ntokens=3904, nsentences=8, sample_size=585
2022-07-12 13:14:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 15998 loss=1221.39697265625, ntokens=3904, nsentences=8, sample_size=584
2022-07-12 13:15:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 15998 loss=1171.91162109375, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 13:15:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 15998 loss=1102.1048583984375, ntokens=3912, nsentences=8, sample_size=584
2022-07-12 13:15:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 15998 loss=1103.32080078125, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 13:15:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 15998 loss=1108.6531982421875, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 13:16:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 15998 loss=1081.9561767578125, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 13:16:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 15998 loss=917.8740234375, ntokens=3920, nsentences=8, sample_size=587
2022-07-12 13:16:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 15998 loss=1028.216064453125, ntokens=3928, nsentences=8, sample_size=590
2022-07-12 13:16:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 15998 loss=1163.104248046875, ntokens=3928, nsentences=8, sample_size=591
2022-07-12 13:16:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 15998 loss=1086.4100341796875, ntokens=3928, nsentences=8, sample_size=589
2022-07-12 13:17:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 15998 loss=1184.4500732421875, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 13:17:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 15998 loss=1260.9361572265625, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 13:17:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 15998 loss=1016.3424072265625, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 13:17:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 15998 loss=1143.036865234375, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 13:18:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 15998 loss=1137.3116455078125, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 13:18:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 15998 loss=1317.887451171875, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 13:18:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 15998 loss=1177.578125, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 13:18:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 15998 loss=1121.7469482421875, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 13:18:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 15998 loss=1229.6424560546875, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 13:19:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 15998 loss=1086.5318603515625, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 13:19:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 15998 loss=1227.3865966796875, ntokens=3952, nsentences=8, sample_size=595
2022-07-12 13:19:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 15998 loss=981.638671875, ntokens=3960, nsentences=8, sample_size=592
2022-07-12 13:19:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 15998 loss=1203.2301025390625, ntokens=3960, nsentences=8, sample_size=594
2022-07-12 13:20:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 15998 loss=1073.2906494140625, ntokens=3960, nsentences=8, sample_size=595
2022-07-12 13:20:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 15998 loss=1091.52880859375, ntokens=3960, nsentences=8, sample_size=596
2022-07-12 13:20:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 15998 loss=1205.5675048828125, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 13:20:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 15998 loss=1036.56787109375, ntokens=3968, nsentences=8, sample_size=593
2022-07-12 13:21:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 15998 loss=1090.861328125, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 13:21:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 15998 loss=1257.0665283203125, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 13:21:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 15998 loss=1153.88037109375, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 13:21:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 15998 loss=1105.154052734375, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 13:21:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 15998 loss=977.6343994140625, ntokens=3976, nsentences=8, sample_size=599
2022-07-12 13:22:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 15998 loss=1182.863037109375, ntokens=3976, nsentences=8, sample_size=597
2022-07-12 13:22:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 15998 loss=1130.5113525390625, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 13:22:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 15998 loss=1037.42578125, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 13:22:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 15998 loss=982.0098266601562, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 13:23:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 15998 loss=1169.65966796875, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 13:23:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 15998 loss=1051.3802490234375, ntokens=3984, nsentences=8, sample_size=599
2022-07-12 13:23:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 15998 loss=1239.520263671875, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 13:23:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 15998 loss=1096.1290283203125, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 13:23:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 15998 loss=1141.5877685546875, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 13:24:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 15998 loss=1243.0657958984375, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 13:24:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 15998 loss=1133.0994873046875, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 13:24:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 15998 loss=1223.58251953125, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 13:24:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 15998 loss=1239.408203125, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 13:25:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 15998 loss=1242.62255859375, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 13:25:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 15998 loss=1177.68359375, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 13:25:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 15998 loss=1218.199462890625, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 13:25:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 15998 loss=1081.3135986328125, ntokens=4008, nsentences=8, sample_size=602
2022-07-12 13:25:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 15998 loss=1007.5858764648438, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 13:26:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 15998 loss=1005.549560546875, ntokens=4008, nsentences=8, sample_size=600
2022-07-12 13:26:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 15998 loss=1051.747314453125, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 13:26:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 15998 loss=1112.7066650390625, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 13:26:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 15998 loss=1096.5777587890625, ntokens=4016, nsentences=8, sample_size=606
2022-07-12 13:27:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 15998 loss=1080.6142578125, ntokens=4016, nsentences=8, sample_size=605
2022-07-12 13:27:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 15998 loss=1222.65771484375, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 13:27:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 15998 loss=1123.5889892578125, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 13:27:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 15998 loss=1114.03076171875, ntokens=4024, nsentences=8, sample_size=605
2022-07-12 13:27:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 15998 loss=1162.8135986328125, ntokens=4024, nsentences=8, sample_size=606
2022-07-12 13:28:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 15998 loss=1133.582763671875, ntokens=4024, nsentences=8, sample_size=603
2022-07-12 13:28:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 15998 loss=1097.3167724609375, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 13:28:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 15998 loss=1191.2061767578125, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 13:28:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 15998 loss=1183.6494140625, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 13:29:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 15998 loss=1223.844970703125, ntokens=4032, nsentences=8, sample_size=605
2022-07-12 13:29:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 15998 loss=1095.7388916015625, ntokens=4032, nsentences=8, sample_size=601
2022-07-12 13:29:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 15998 loss=1236.875, ntokens=4032, nsentences=8, sample_size=607
2022-07-12 13:29:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 15998 loss=1142.3468017578125, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 13:29:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 15998 loss=1152.8154296875, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 13:30:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 15998 loss=1156.5738525390625, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 13:30:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 15998 loss=1088.0032958984375, ntokens=4040, nsentences=8, sample_size=607
2022-07-12 13:30:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 15998 loss=1221.4425048828125, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 13:30:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 15998 loss=1087.1519775390625, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 13:30:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 15998 loss=1115.2386474609375, ntokens=4048, nsentences=8, sample_size=608
2022-07-12 13:31:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 15998 loss=1142.86474609375, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 13:31:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 15998 loss=986.4814453125, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 13:31:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 15998 loss=1102.603271484375, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 13:31:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 15998 loss=1059.43505859375, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 13:32:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 15998 loss=1242.486328125, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 13:32:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 15998 loss=1162.454833984375, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 13:32:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 15998 loss=1087.0228271484375, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 13:32:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 15998 loss=1142.99755859375, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 13:32:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 15998 loss=1305.802978515625, ntokens=4064, nsentences=8, sample_size=609
2022-07-12 13:33:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 15998 loss=1110.574462890625, ntokens=4064, nsentences=8, sample_size=608
2022-07-12 13:33:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 15998 loss=1190.4642333984375, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 13:33:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 15998 loss=1136.462890625, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 13:33:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 15998 loss=1073.0546875, ntokens=4064, nsentences=8, sample_size=612
2022-07-12 13:34:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 15998 loss=1125.6015625, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 13:34:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 15998 loss=1210.3831787109375, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 13:34:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 15998 loss=1216.3177490234375, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 13:34:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 15998 loss=1173.5142822265625, ntokens=4072, nsentences=8, sample_size=608
2022-07-12 13:34:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 15998 loss=1213.800537109375, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 13:35:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 15998 loss=1061.44677734375, ntokens=4080, nsentences=8, sample_size=613
2022-07-12 13:35:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 15998 loss=1171.0723876953125, ntokens=4080, nsentences=8, sample_size=614
2022-07-12 13:35:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 15998 loss=1179.99462890625, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 13:35:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 15998 loss=1190.8623046875, ntokens=4080, nsentences=8, sample_size=611
2022-07-12 13:36:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 15998 loss=1326.4434814453125, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 13:36:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 15998 loss=1173.0120849609375, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:36:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 15998 loss=1183.0020751953125, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:36:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 15998 loss=1127.932861328125, ntokens=4088, nsentences=8, sample_size=614
2022-07-12 13:36:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 15998 loss=1191.158203125, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:37:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 15998 loss=1113.389404296875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 13:37:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 15998 loss=1121.234130859375, ntokens=4096, nsentences=8, sample_size=613
2022-07-12 13:37:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 15998 loss=1368.974609375, ntokens=4096, nsentences=8, sample_size=612
2022-07-12 13:37:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 15998 loss=1014.427490234375, ntokens=4096, nsentences=8, sample_size=614
2022-07-12 13:38:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 15998 loss=1246.8798828125, ntokens=4096, nsentences=8, sample_size=616
2022-07-12 13:38:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 15998 loss=1168.9556884765625, ntokens=4096, nsentences=8, sample_size=615
2022-07-12 13:38:29 | INFO | valid | valid on 'valid' subset | loss 2.729 | ppl 6.63 | wps 0 | wpb 6.2902e+07 | bsz 127981
2022-07-12 13:38:36 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/RoBERTa_100_finetune.pt
2022-07-12 13:38:38 | INFO | fairseq.tasks.masked_lm | dictionary: 39984 types
2022-07-12 13:38:48 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'RoBERTa', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/RoBERTa_100_finetune.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17891', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': True, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 1, 'max_update': 125000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/dahmanir/lisa/Models/RoBERTa_100.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'roberta', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_dropout': 0.0, 'pooler_dropout': 0.0, 'max_source_positions': 512, 'no_token_positional_embeddings': False, 'encoder_learned_pos': True, 'layernorm_embedding': True, 'no_scale_embedding': True, 'activation_fn': 'gelu', 'encoder_normalize_before': False, 'pooler_activation_fn': 'tanh', 'untie_weights_roberta': False, 'adaptive_input': False, 'encoder_layerdrop': 0.0, 'encoder_layers_to_keep': None, 'quant_noise_pq': 0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0, 'spectral_norm_classification_head': False}, 'task': {'_name': 'masked_lm', 'data': 'lisa/Datasets/europarl_nl_bin', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 125000.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
2022-07-12 13:38:48 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 13:38:48 | INFO | fairseq.tasks.masked_lm | loaded 127997 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 13:38:48 | WARNING | fairseq.tasks.fairseq_task | 16 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[91279, 98239, 123892, 104545, 120813, 113078, 106642, 109767, 110720, 105213]
2022-07-12 13:38:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 15998 loss=987.5928955078125, ntokens=3392, nsentences=8, sample_size=510
2022-07-12 13:39:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 15998 loss=991.1448364257812, ntokens=3496, nsentences=8, sample_size=524
2022-07-12 13:39:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 15998 loss=1024.5020751953125, ntokens=3544, nsentences=8, sample_size=531
2022-07-12 13:39:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 15998 loss=944.7779541015625, ntokens=3584, nsentences=8, sample_size=538
2022-07-12 13:39:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 15998 loss=1013.3684692382812, ntokens=3608, nsentences=8, sample_size=543
2022-07-12 13:39:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 15998 loss=1079.8399658203125, ntokens=3632, nsentences=8, sample_size=544
2022-07-12 13:40:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 15998 loss=1097.4287109375, ntokens=3648, nsentences=8, sample_size=546
2022-07-12 13:40:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 15998 loss=1000.8108520507812, ntokens=3664, nsentences=8, sample_size=550
2022-07-12 13:40:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 15998 loss=1023.3270263671875, ntokens=3680, nsentences=8, sample_size=552
2022-07-12 13:40:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 15998 loss=886.2301025390625, ntokens=3696, nsentences=8, sample_size=556
2022-07-12 13:40:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 15998 loss=968.7628784179688, ntokens=3704, nsentences=8, sample_size=557
2022-07-12 13:41:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 15998 loss=1066.6995849609375, ntokens=3720, nsentences=8, sample_size=559
2022-07-12 13:41:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 15998 loss=1032.87548828125, ntokens=3728, nsentences=8, sample_size=559
2022-07-12 13:41:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 15998 loss=953.2240600585938, ntokens=3736, nsentences=8, sample_size=560
2022-07-12 13:41:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 15998 loss=1003.5755615234375, ntokens=3744, nsentences=8, sample_size=560
2022-07-12 13:42:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 15998 loss=1151.1131591796875, ntokens=3752, nsentences=8, sample_size=565
2022-07-12 13:42:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 15998 loss=1064.8751220703125, ntokens=3760, nsentences=8, sample_size=565
2022-07-12 13:42:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 15998 loss=1150.9320068359375, ntokens=3768, nsentences=8, sample_size=566
2022-07-12 13:42:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 15998 loss=1061.1192626953125, ntokens=3768, nsentences=8, sample_size=565
2022-07-12 13:42:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 15998 loss=1120.4302978515625, ntokens=3776, nsentences=8, sample_size=567
2022-07-12 13:43:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 15998 loss=1075.4080810546875, ntokens=3784, nsentences=8, sample_size=568
2022-07-12 13:43:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 15998 loss=1197.0870361328125, ntokens=3792, nsentences=8, sample_size=570
2022-07-12 13:43:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 15998 loss=1264.3668212890625, ntokens=3792, nsentences=8, sample_size=568
2022-07-12 13:43:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 15998 loss=1107.466552734375, ntokens=3800, nsentences=8, sample_size=571
2022-07-12 13:43:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 15998 loss=1019.5775756835938, ntokens=3808, nsentences=8, sample_size=569
2022-07-12 13:44:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 15998 loss=1143.2669677734375, ntokens=3808, nsentences=8, sample_size=570
2022-07-12 13:44:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 15998 loss=1153.788330078125, ntokens=3816, nsentences=8, sample_size=574
2022-07-12 13:44:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 15998 loss=1018.4578247070312, ntokens=3816, nsentences=8, sample_size=572
2022-07-12 13:44:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 15998 loss=1051.5244140625, ntokens=3824, nsentences=8, sample_size=575
2022-07-12 13:44:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 15998 loss=1092.14111328125, ntokens=3832, nsentences=8, sample_size=573
2022-07-12 13:45:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 15998 loss=1228.8184814453125, ntokens=3832, nsentences=8, sample_size=575
2022-07-12 13:45:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 15998 loss=1095.410888671875, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 13:45:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 15998 loss=970.3515014648438, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 13:45:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 15998 loss=1145.228271484375, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 13:46:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 15998 loss=921.3668823242188, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 13:46:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 15998 loss=1075.892578125, ntokens=3848, nsentences=8, sample_size=577
2022-07-12 13:46:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 15998 loss=1013.2401123046875, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 13:46:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 15998 loss=953.9989013671875, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 13:46:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 15998 loss=1106.1563720703125, ntokens=3864, nsentences=8, sample_size=580
2022-07-12 13:47:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 15998 loss=1050.4461669921875, ntokens=3864, nsentences=8, sample_size=581
2022-07-12 13:47:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 15998 loss=1054.4306640625, ntokens=3872, nsentences=8, sample_size=581
2022-07-12 13:47:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 15998 loss=1046.2982177734375, ntokens=3872, nsentences=8, sample_size=583
2022-07-12 13:47:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 15998 loss=1191.6256103515625, ntokens=3872, nsentences=8, sample_size=582
2022-07-12 13:48:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 15998 loss=1160.4739990234375, ntokens=3880, nsentences=8, sample_size=582
2022-07-12 13:48:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 15998 loss=1107.359375, ntokens=3880, nsentences=8, sample_size=580
2022-07-12 13:48:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 15998 loss=1063.8192138671875, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 13:48:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 15998 loss=1185.14306640625, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 13:49:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 15998 loss=1082.0521240234375, ntokens=3888, nsentences=8, sample_size=582
2022-07-12 13:49:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 15998 loss=1084.3720703125, ntokens=3896, nsentences=8, sample_size=584
2022-07-12 13:49:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 15998 loss=1123.692626953125, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 13:49:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 15998 loss=1144.6805419921875, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 13:49:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 15998 loss=1235.0452880859375, ntokens=3904, nsentences=8, sample_size=587
2022-07-12 13:50:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 15998 loss=1225.9993896484375, ntokens=3904, nsentences=8, sample_size=585
2022-07-12 13:50:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 15998 loss=1225.1258544921875, ntokens=3904, nsentences=8, sample_size=584
2022-07-12 13:50:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 15998 loss=1169.8658447265625, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 13:50:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 15998 loss=1093.362060546875, ntokens=3912, nsentences=8, sample_size=584
2022-07-12 13:51:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 15998 loss=1090.821044921875, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 13:51:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 15998 loss=1108.6378173828125, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 13:51:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 15998 loss=1084.515869140625, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 13:51:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 15998 loss=912.39794921875, ntokens=3920, nsentences=8, sample_size=587
2022-07-12 13:51:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 15998 loss=1025.9404296875, ntokens=3928, nsentences=8, sample_size=590
2022-07-12 13:52:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 15998 loss=1152.9466552734375, ntokens=3928, nsentences=8, sample_size=591
2022-07-12 13:52:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 15998 loss=1079.305908203125, ntokens=3928, nsentences=8, sample_size=589
2022-07-12 13:52:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 15998 loss=1187.0252685546875, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 13:52:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 15998 loss=1252.83935546875, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 13:53:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 15998 loss=1008.003662109375, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 13:53:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 15998 loss=1138.5953369140625, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 13:53:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 15998 loss=1146.467529296875, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 13:53:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 15998 loss=1303.61572265625, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 13:53:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 15998 loss=1178.97998046875, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 13:54:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 15998 loss=1108.29931640625, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 13:54:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 15998 loss=1234.9351806640625, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 13:54:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 15998 loss=1087.4207763671875, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 13:54:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 15998 loss=1223.8701171875, ntokens=3952, nsentences=8, sample_size=595
2022-07-12 13:55:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 15998 loss=999.8501586914062, ntokens=3960, nsentences=8, sample_size=592
2022-07-12 13:55:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 15998 loss=1209.4981689453125, ntokens=3960, nsentences=8, sample_size=594
2022-07-12 13:55:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 15998 loss=1084.1243896484375, ntokens=3960, nsentences=8, sample_size=595
2022-07-12 13:55:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 15998 loss=1086.68603515625, ntokens=3960, nsentences=8, sample_size=596
2022-07-12 13:56:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 15998 loss=1206.24072265625, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 13:56:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 15998 loss=1042.51171875, ntokens=3968, nsentences=8, sample_size=593
2022-07-12 13:56:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 15998 loss=1075.2352294921875, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 13:56:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 15998 loss=1265.1131591796875, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 13:56:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 15998 loss=1147.6876220703125, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 13:57:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 15998 loss=1081.9781494140625, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 13:57:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 15998 loss=986.8509521484375, ntokens=3976, nsentences=8, sample_size=599
2022-07-12 13:57:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 15998 loss=1189.46533203125, ntokens=3976, nsentences=8, sample_size=597
2022-07-12 13:57:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 15998 loss=1128.3292236328125, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 13:58:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 15998 loss=1035.8778076171875, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 13:58:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 15998 loss=983.8817138671875, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 13:58:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 15998 loss=1156.275146484375, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 13:58:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 15998 loss=1052.2547607421875, ntokens=3984, nsentences=8, sample_size=599
2022-07-12 13:58:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 15998 loss=1237.7294921875, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 13:59:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 15998 loss=1107.106689453125, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 13:59:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 15998 loss=1140.2120361328125, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 13:59:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 15998 loss=1231.24560546875, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 13:59:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 15998 loss=1116.9146728515625, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 13:59:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 15998 loss=1222.5496826171875, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:00:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 15998 loss=1240.616455078125, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:00:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 15998 loss=1243.8349609375, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:00:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 15998 loss=1168.5526123046875, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:00:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 15998 loss=1209.9180908203125, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 14:01:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 15998 loss=1091.5281982421875, ntokens=4008, nsentences=8, sample_size=602
2022-07-12 14:01:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 15998 loss=989.9100952148438, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 14:01:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 15998 loss=1002.411376953125, ntokens=4008, nsentences=8, sample_size=600
2022-07-12 14:01:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 15998 loss=1063.3658447265625, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 14:01:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 15998 loss=1107.225830078125, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 14:02:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 15998 loss=1084.816162109375, ntokens=4016, nsentences=8, sample_size=606
2022-07-12 14:02:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 15998 loss=1084.39208984375, ntokens=4016, nsentences=8, sample_size=605
2022-07-12 14:02:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 15998 loss=1223.2567138671875, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 14:02:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 15998 loss=1104.2322998046875, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 14:03:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 15998 loss=1107.020263671875, ntokens=4024, nsentences=8, sample_size=605
2022-07-12 14:03:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 15998 loss=1181.4801025390625, ntokens=4024, nsentences=8, sample_size=606
2022-07-12 14:03:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 15998 loss=1133.2103271484375, ntokens=4024, nsentences=8, sample_size=603
2022-07-12 14:03:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 15998 loss=1082.3338623046875, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 14:03:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 15998 loss=1191.0584716796875, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 14:04:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 15998 loss=1180.25341796875, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 14:04:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 15998 loss=1224.519287109375, ntokens=4032, nsentences=8, sample_size=605
2022-07-12 14:04:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 15998 loss=1096.5540771484375, ntokens=4032, nsentences=8, sample_size=601
2022-07-12 14:04:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 15998 loss=1234.41796875, ntokens=4032, nsentences=8, sample_size=607
2022-07-12 14:05:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 15998 loss=1145.1744384765625, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 14:05:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 15998 loss=1161.391357421875, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 14:05:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 15998 loss=1152.1390380859375, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 14:05:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 15998 loss=1085.540283203125, ntokens=4040, nsentences=8, sample_size=607
2022-07-12 14:05:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 15998 loss=1234.9541015625, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 14:06:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 15998 loss=1074.2811279296875, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 14:06:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 15998 loss=1116.9173583984375, ntokens=4048, nsentences=8, sample_size=608
2022-07-12 14:06:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 15998 loss=1143.065673828125, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 14:06:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 15998 loss=994.1648559570312, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 14:07:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 15998 loss=1108.0474853515625, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 14:07:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 15998 loss=1065.840576171875, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 14:07:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 15998 loss=1247.3687744140625, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 14:07:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 15998 loss=1161.9217529296875, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 14:07:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 15998 loss=1072.4351806640625, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 14:08:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 15998 loss=1135.008544921875, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 14:08:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 15998 loss=1302.1700439453125, ntokens=4064, nsentences=8, sample_size=609
2022-07-12 14:08:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 15998 loss=1104.8590087890625, ntokens=4064, nsentences=8, sample_size=608
2022-07-12 14:08:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 15998 loss=1190.89453125, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 14:09:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 15998 loss=1128.5330810546875, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 14:09:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 15998 loss=1103.507568359375, ntokens=4064, nsentences=8, sample_size=612
2022-07-12 14:09:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 15998 loss=1109.5975341796875, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 14:09:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 15998 loss=1228.39306640625, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 14:09:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 15998 loss=1222.0450439453125, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 14:10:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 15998 loss=1165.304931640625, ntokens=4072, nsentences=8, sample_size=608
2022-07-12 14:10:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 15998 loss=1234.2313232421875, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 14:10:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 15998 loss=1045.985107421875, ntokens=4080, nsentences=8, sample_size=613
2022-07-12 14:10:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 15998 loss=1165.23828125, ntokens=4080, nsentences=8, sample_size=614
2022-07-12 14:11:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 15998 loss=1188.5191650390625, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 14:11:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 15998 loss=1201.10986328125, ntokens=4080, nsentences=8, sample_size=611
2022-07-12 14:11:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 15998 loss=1314.7899169921875, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 14:11:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 15998 loss=1177.3768310546875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:11:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 15998 loss=1171.5814208984375, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:12:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 15998 loss=1125.51611328125, ntokens=4088, nsentences=8, sample_size=614
2022-07-12 14:12:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 15998 loss=1196.3529052734375, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:12:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 15998 loss=1116.8258056640625, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:12:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 15998 loss=1117.6314697265625, ntokens=4096, nsentences=8, sample_size=613
2022-07-12 14:13:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 15998 loss=1362.8983154296875, ntokens=4096, nsentences=8, sample_size=612
2022-07-12 14:13:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 15998 loss=1022.1885986328125, ntokens=4096, nsentences=8, sample_size=614
2022-07-12 14:13:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 15998 loss=1239.6258544921875, ntokens=4096, nsentences=8, sample_size=616
2022-07-12 14:13:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 15998 loss=1161.560302734375, ntokens=4096, nsentences=8, sample_size=615
2022-07-12 14:13:53 | INFO | valid | valid on 'valid' subset | loss 2.724 | ppl 6.61 | wps 0 | wpb 6.2902e+07 | bsz 127981
2022-07-12 14:13:59 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/robbert.pt
2022-07-12 14:14:05 | INFO | fairseq.tasks.masked_lm | dictionary: 39984 types
2022-07-12 14:14:15 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': '', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/robbert.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:6666', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 160000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [256], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '.', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 100, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=1, log_format='simple', tensorboard_logdir='', seed=1, cpu=False, fp16=False, memory_efficient_fp16=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, criterion='masked_lm', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=None, max_sentences=4, required_batch_size_multiple=8, dataset_impl=None, train_subset='train', valid_subset='valid', validate_interval=1, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, max_sentences_valid=4, curriculum=0, distributed_world_size=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://localhost:6666', distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='no_c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, arch='roberta_base', max_epoch=0, max_update=160000, clip_norm=0.0, sentence_avg=False, update_freq=[256], lr=[0.0007], use_bmuf=False, save_dir='.', restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=100, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, encoder_layerdrop=0, encoder_layers_to_keep=None, adam_betas='(0.9,0.98)', adam_eps=1e-06, weight_decay=0.01, force_anneal=None, warmup_updates=1000, end_learning_rate=0.0, power=1.0, total_num_update=160000, data='lisa/Datasets/europarl_nl_bin', sample_break_mode='complete', tokens_per_sample=512, mask_prob=0.15, leave_unmasked_prob=0.1, random_token_prob=0.1, freq_weighted_replacement=False, mask_whole_words=False, dropout=0.1, attention_dropout=0.1, encoder_layers=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_attention_heads=12, activation_fn='gelu', pooler_activation_fn='tanh', activation_dropout=0.0, pooler_dropout=0.0, max_positions=512, batch_size=8, path='lisa/Models/robbert.pt', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_base', no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': 'lisa/Datasets/europarl_nl_bin', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 1000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 160000.0, 'lr': [0.0007]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-07-12 14:14:15 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 14:14:15 | INFO | fairseq.tasks.masked_lm | loaded 127997 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 14:14:15 | WARNING | fairseq.tasks.fairseq_task | 16 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[91279, 98239, 123892, 104545, 120813, 113078, 106642, 109767, 110720, 105213]
2022-07-12 14:14:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 15998 loss=832.1734619140625, ntokens=3392, nsentences=8, sample_size=510
2022-07-12 14:14:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 15998 loss=797.3486328125, ntokens=3496, nsentences=8, sample_size=524
2022-07-12 14:14:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 15998 loss=799.1851196289062, ntokens=3544, nsentences=8, sample_size=531
2022-07-12 14:15:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 15998 loss=753.99853515625, ntokens=3584, nsentences=8, sample_size=538
2022-07-12 14:15:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 15998 loss=820.4097900390625, ntokens=3608, nsentences=8, sample_size=543
2022-07-12 14:15:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 15998 loss=939.06787109375, ntokens=3632, nsentences=8, sample_size=544
2022-07-12 14:16:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 15998 loss=925.5313720703125, ntokens=3648, nsentences=8, sample_size=546
2022-07-12 14:16:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 15998 loss=822.3956909179688, ntokens=3664, nsentences=8, sample_size=550
2022-07-12 14:16:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 15998 loss=832.31005859375, ntokens=3680, nsentences=8, sample_size=552
2022-07-12 14:16:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 15998 loss=765.1663208007812, ntokens=3696, nsentences=8, sample_size=556
2022-07-12 14:17:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 15998 loss=815.0615844726562, ntokens=3704, nsentences=8, sample_size=557
2022-07-12 14:17:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 15998 loss=877.8607788085938, ntokens=3720, nsentences=8, sample_size=559
2022-07-12 14:17:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 15998 loss=888.7767944335938, ntokens=3728, nsentences=8, sample_size=559
2022-07-12 14:17:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 15998 loss=787.6810302734375, ntokens=3736, nsentences=8, sample_size=560
2022-07-12 14:18:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 15998 loss=851.2971801757812, ntokens=3744, nsentences=8, sample_size=560
2022-07-12 14:18:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 15998 loss=927.4442749023438, ntokens=3752, nsentences=8, sample_size=565
2022-07-12 14:18:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 15998 loss=841.802001953125, ntokens=3760, nsentences=8, sample_size=565
2022-07-12 14:18:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 15998 loss=929.091796875, ntokens=3768, nsentences=8, sample_size=566
2022-07-12 14:19:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 15998 loss=848.73681640625, ntokens=3768, nsentences=8, sample_size=565
2022-07-12 14:19:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 15998 loss=874.863037109375, ntokens=3776, nsentences=8, sample_size=567
2022-07-12 14:19:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 15998 loss=815.4151000976562, ntokens=3784, nsentences=8, sample_size=568
2022-07-12 14:19:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 15998 loss=913.3851318359375, ntokens=3792, nsentences=8, sample_size=570
2022-07-12 14:20:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 15998 loss=969.4293212890625, ntokens=3792, nsentences=8, sample_size=568
2022-07-12 14:20:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 15998 loss=907.3512573242188, ntokens=3800, nsentences=8, sample_size=571
2022-07-12 14:20:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 15998 loss=830.660888671875, ntokens=3808, nsentences=8, sample_size=569
2022-07-12 14:21:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 15998 loss=848.6097412109375, ntokens=3808, nsentences=8, sample_size=570
2022-07-12 14:21:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 15998 loss=911.3662109375, ntokens=3816, nsentences=8, sample_size=574
2022-07-12 14:21:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 15998 loss=785.0137329101562, ntokens=3816, nsentences=8, sample_size=572
2022-07-12 14:21:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 15998 loss=838.0145263671875, ntokens=3824, nsentences=8, sample_size=575
2022-07-12 14:22:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 15998 loss=894.47802734375, ntokens=3832, nsentences=8, sample_size=573
2022-07-12 14:22:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 15998 loss=937.9851684570312, ntokens=3832, nsentences=8, sample_size=575
2022-07-12 14:22:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 15998 loss=845.168701171875, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 14:22:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 15998 loss=841.9056396484375, ntokens=3840, nsentences=8, sample_size=576
2022-07-12 14:23:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 15998 loss=1006.1608276367188, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 14:23:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 15998 loss=770.09130859375, ntokens=3848, nsentences=8, sample_size=576
2022-07-12 14:23:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 15998 loss=868.9332275390625, ntokens=3848, nsentences=8, sample_size=577
2022-07-12 14:24:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 15998 loss=767.4212646484375, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 14:24:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 15998 loss=767.9876098632812, ntokens=3856, nsentences=8, sample_size=578
2022-07-12 14:24:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 15998 loss=857.0571899414062, ntokens=3864, nsentences=8, sample_size=580
2022-07-12 14:24:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 15998 loss=774.5043334960938, ntokens=3864, nsentences=8, sample_size=581
2022-07-12 14:25:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 15998 loss=869.2686157226562, ntokens=3872, nsentences=8, sample_size=581
2022-07-12 14:25:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 15998 loss=808.447998046875, ntokens=3872, nsentences=8, sample_size=583
2022-07-12 14:25:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 15998 loss=975.8866577148438, ntokens=3872, nsentences=8, sample_size=582
2022-07-12 14:26:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 15998 loss=980.6554565429688, ntokens=3880, nsentences=8, sample_size=582
2022-07-12 14:26:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 15998 loss=881.062744140625, ntokens=3880, nsentences=8, sample_size=580
2022-07-12 14:26:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 15998 loss=878.908203125, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 14:26:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 15998 loss=975.14794921875, ntokens=3888, nsentences=8, sample_size=583
2022-07-12 14:27:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 15998 loss=836.0082397460938, ntokens=3888, nsentences=8, sample_size=582
2022-07-12 14:27:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 15998 loss=889.847900390625, ntokens=3896, nsentences=8, sample_size=584
2022-07-12 14:27:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 15998 loss=865.5216064453125, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 14:28:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 15998 loss=873.6734008789062, ntokens=3896, nsentences=8, sample_size=585
2022-07-12 14:28:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 15998 loss=978.7030639648438, ntokens=3904, nsentences=8, sample_size=587
2022-07-12 14:28:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 15998 loss=1012.6233520507812, ntokens=3904, nsentences=8, sample_size=585
2022-07-12 14:29:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 15998 loss=1006.9738159179688, ntokens=3904, nsentences=8, sample_size=584
2022-07-12 14:29:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 15998 loss=952.6358032226562, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 14:29:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 15998 loss=815.1303100585938, ntokens=3912, nsentences=8, sample_size=584
2022-07-12 14:29:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 15998 loss=887.1378173828125, ntokens=3912, nsentences=8, sample_size=586
2022-07-12 14:30:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 15998 loss=776.5592041015625, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 14:30:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 15998 loss=909.128662109375, ntokens=3920, nsentences=8, sample_size=588
2022-07-12 14:30:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 15998 loss=746.4434814453125, ntokens=3920, nsentences=8, sample_size=587
2022-07-12 14:31:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 15998 loss=758.8648681640625, ntokens=3928, nsentences=8, sample_size=590
2022-07-12 14:31:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 15998 loss=889.8353271484375, ntokens=3928, nsentences=8, sample_size=591
2022-07-12 14:31:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 15998 loss=911.990234375, ntokens=3928, nsentences=8, sample_size=589
2022-07-12 14:31:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 15998 loss=937.164306640625, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 14:32:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 15998 loss=1000.6582641601562, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 14:32:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 15998 loss=860.0604858398438, ntokens=3936, nsentences=8, sample_size=592
2022-07-12 14:32:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 15998 loss=1006.3500366210938, ntokens=3936, nsentences=8, sample_size=590
2022-07-12 14:33:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 15998 loss=862.789794921875, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 14:33:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 15998 loss=986.9824829101562, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 14:33:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 15998 loss=923.802490234375, ntokens=3944, nsentences=8, sample_size=591
2022-07-12 14:33:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 15998 loss=875.5960693359375, ntokens=3944, nsentences=8, sample_size=592
2022-07-12 14:34:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 15998 loss=969.4281616210938, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 14:34:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 15998 loss=862.2132568359375, ntokens=3952, nsentences=8, sample_size=592
2022-07-12 14:34:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 15998 loss=1042.886474609375, ntokens=3952, nsentences=8, sample_size=595
2022-07-12 14:35:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 15998 loss=799.5374755859375, ntokens=3960, nsentences=8, sample_size=592
2022-07-12 14:35:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 15998 loss=984.7794799804688, ntokens=3960, nsentences=8, sample_size=594
2022-07-12 14:35:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 15998 loss=865.5643310546875, ntokens=3960, nsentences=8, sample_size=595
2022-07-12 14:36:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 15998 loss=838.1015625, ntokens=3960, nsentences=8, sample_size=596
2022-07-12 14:36:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 15998 loss=977.0537719726562, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 14:36:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 15998 loss=771.2892456054688, ntokens=3968, nsentences=8, sample_size=593
2022-07-12 14:36:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 15998 loss=923.4388427734375, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 14:37:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 15998 loss=1097.6268310546875, ntokens=3968, nsentences=8, sample_size=597
2022-07-12 14:37:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 15998 loss=921.0699462890625, ntokens=3968, nsentences=8, sample_size=596
2022-07-12 14:37:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 15998 loss=895.9732666015625, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 14:38:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 15998 loss=745.0914306640625, ntokens=3976, nsentences=8, sample_size=599
2022-07-12 14:38:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 15998 loss=952.2744140625, ntokens=3976, nsentences=8, sample_size=597
2022-07-12 14:38:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 15998 loss=916.880615234375, ntokens=3976, nsentences=8, sample_size=595
2022-07-12 14:38:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 15998 loss=777.4635009765625, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 14:39:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 15998 loss=830.1624755859375, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 14:39:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 15998 loss=893.3619384765625, ntokens=3984, nsentences=8, sample_size=597
2022-07-12 14:39:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 15998 loss=917.3150634765625, ntokens=3984, nsentences=8, sample_size=599
2022-07-12 14:40:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 15998 loss=988.107421875, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 14:40:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 15998 loss=917.8527221679688, ntokens=3992, nsentences=8, sample_size=599
2022-07-12 14:40:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 15998 loss=909.7142944335938, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 14:40:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 15998 loss=1046.8134765625, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 14:41:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 15998 loss=939.0490112304688, ntokens=3992, nsentences=8, sample_size=600
2022-07-12 14:41:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 15998 loss=922.2344970703125, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:41:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 15998 loss=979.7050170898438, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:41:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 15998 loss=985.3123168945312, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:42:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 15998 loss=982.7811889648438, ntokens=4000, nsentences=8, sample_size=600
2022-07-12 14:42:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 15998 loss=1010.5501708984375, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 14:42:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 15998 loss=833.9876098632812, ntokens=4008, nsentences=8, sample_size=602
2022-07-12 14:43:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 15998 loss=816.2992553710938, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 14:43:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 15998 loss=829.81640625, ntokens=4008, nsentences=8, sample_size=600
2022-07-12 14:43:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 15998 loss=847.4943237304688, ntokens=4008, nsentences=8, sample_size=601
2022-07-12 14:43:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 15998 loss=827.4580078125, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 14:44:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 15998 loss=928.5587768554688, ntokens=4016, nsentences=8, sample_size=606
2022-07-12 14:44:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 15998 loss=858.6586303710938, ntokens=4016, nsentences=8, sample_size=605
2022-07-12 14:44:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 15998 loss=923.3115234375, ntokens=4016, nsentences=8, sample_size=601
2022-07-12 14:45:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 15998 loss=869.656494140625, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 14:45:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 15998 loss=890.2562866210938, ntokens=4024, nsentences=8, sample_size=605
2022-07-12 14:45:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 15998 loss=975.7466430664062, ntokens=4024, nsentences=8, sample_size=606
2022-07-12 14:45:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 15998 loss=910.657470703125, ntokens=4024, nsentences=8, sample_size=603
2022-07-12 14:46:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 15998 loss=847.239501953125, ntokens=4024, nsentences=8, sample_size=602
2022-07-12 14:46:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 15998 loss=916.2236328125, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 14:46:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 15998 loss=915.3641967773438, ntokens=4032, nsentences=8, sample_size=604
2022-07-12 14:47:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 15998 loss=1022.3826293945312, ntokens=4032, nsentences=8, sample_size=605
2022-07-12 14:47:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 15998 loss=947.6972045898438, ntokens=4032, nsentences=8, sample_size=601
2022-07-12 14:47:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 15998 loss=934.3745727539062, ntokens=4032, nsentences=8, sample_size=607
2022-07-12 14:47:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 15998 loss=888.26806640625, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 14:48:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 15998 loss=922.339599609375, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 14:48:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 15998 loss=913.639404296875, ntokens=4040, nsentences=8, sample_size=606
2022-07-12 14:48:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 15998 loss=925.0027465820312, ntokens=4040, nsentences=8, sample_size=607
2022-07-12 14:48:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 15998 loss=1001.848388671875, ntokens=4040, nsentences=8, sample_size=605
2022-07-12 14:49:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 15998 loss=877.8850708007812, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 14:49:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 15998 loss=906.0481567382812, ntokens=4048, nsentences=8, sample_size=608
2022-07-12 14:49:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 15998 loss=893.4203491210938, ntokens=4048, nsentences=8, sample_size=606
2022-07-12 14:50:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 15998 loss=729.7095336914062, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 14:50:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 15998 loss=835.6052856445312, ntokens=4048, nsentences=8, sample_size=607
2022-07-12 14:50:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 15998 loss=838.8392333984375, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 14:50:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 15998 loss=903.4732666015625, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 14:51:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 15998 loss=967.4341430664062, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 14:51:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 15998 loss=823.5703125, ntokens=4056, nsentences=8, sample_size=608
2022-07-12 14:51:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 15998 loss=887.9616088867188, ntokens=4056, nsentences=8, sample_size=609
2022-07-12 14:52:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 15998 loss=936.9647827148438, ntokens=4064, nsentences=8, sample_size=609
2022-07-12 14:52:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 15998 loss=866.4617309570312, ntokens=4064, nsentences=8, sample_size=608
2022-07-12 14:52:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 15998 loss=920.2490234375, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 14:52:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 15998 loss=876.8299560546875, ntokens=4064, nsentences=8, sample_size=610
2022-07-12 14:53:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 15998 loss=856.4140014648438, ntokens=4064, nsentences=8, sample_size=612
2022-07-12 14:53:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 15998 loss=867.4066772460938, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 14:53:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 15998 loss=962.608154296875, ntokens=4072, nsentences=8, sample_size=612
2022-07-12 14:53:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 15998 loss=998.3829956054688, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 14:54:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 15998 loss=960.689453125, ntokens=4072, nsentences=8, sample_size=608
2022-07-12 14:54:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 15998 loss=863.8330078125, ntokens=4072, nsentences=8, sample_size=611
2022-07-12 14:54:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 15998 loss=831.0343017578125, ntokens=4080, nsentences=8, sample_size=613
2022-07-12 14:55:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 15998 loss=938.7719116210938, ntokens=4080, nsentences=8, sample_size=614
2022-07-12 14:55:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 15998 loss=907.2482299804688, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 14:55:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 15998 loss=962.7229614257812, ntokens=4080, nsentences=8, sample_size=611
2022-07-12 14:55:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 15998 loss=989.1550903320312, ntokens=4080, nsentences=8, sample_size=612
2022-07-12 14:56:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 15998 loss=975.647216796875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:56:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 15998 loss=921.6691284179688, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:56:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 15998 loss=950.0170288085938, ntokens=4088, nsentences=8, sample_size=614
2022-07-12 14:57:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 15998 loss=909.149169921875, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:57:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 15998 loss=851.2562255859375, ntokens=4088, nsentences=8, sample_size=613
2022-07-12 14:57:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 15998 loss=854.9937133789062, ntokens=4096, nsentences=8, sample_size=613
2022-07-12 14:57:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 15998 loss=1054.773193359375, ntokens=4096, nsentences=8, sample_size=612
2022-07-12 14:58:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 15998 loss=820.3189086914062, ntokens=4096, nsentences=8, sample_size=614
2022-07-12 14:58:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 15998 loss=1009.3872680664062, ntokens=4096, nsentences=8, sample_size=616
2022-07-12 14:58:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 15998 loss=890.9197998046875, ntokens=4096, nsentences=8, sample_size=615
2022-07-12 14:58:59 | INFO | valid | valid on 'valid' subset | loss 2.172 | ppl 4.51 | wps 0 | wpb 6.2902e+07 | bsz 127981
2022-07-12 14:59:05 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/BART_10_finetune.pt
2022-07-12 14:59:07 | INFO | fairseq.tasks.denoising | dictionary: 39984 types
2022-07-12 14:59:17 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'BART', 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/BART_10_finetune.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19856', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 3200, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/dahmanir/lisa/Models/BART_10.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=200, log_format='json', log_file=None, tensorboard_logdir=None, wandb_project='BART', azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='denoising', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=3200, batch_size=8, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3200, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=2, distributed_num_procs=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=2, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='bart_base', max_epoch=0, max_update=500000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[32], lr=[1e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='/home/dahmanir/lisa/Models/BART_10.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='lisa/Datasets/europarl_nl_bin', tokens_per_sample=512, sample_break_mode='complete_doc', mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=3.5, permute_sentences=1.0, mask_length='span-poisson', replace_length=1, shorten_method='none', shorten_data_split_list='', adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=500, force_anneal=None, end_learning_rate=0.0, power=1.0, total_num_update='500000', pad=1, eos=2, unk=3, dropout=0.1, attention_dropout=0.1, no_seed_provided=False, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layers=6, encoder_attention_heads=12, decoder_layers=6, decoder_attention_heads=12, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=True, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=3072, decoder_normalize_before=False, decoder_learned_pos=True, relu_dropout=0.0, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=768, decoder_input_dim=768, no_scale_embedding=True, layernorm_embedding=True, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='bart_base', activation_dropout=0.0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, path='lisa/Models/BART_10_finetune.pt'), 'task': Namespace(no_progress_bar=False, log_interval=200, log_format='json', log_file=None, tensorboard_logdir=None, wandb_project='BART', azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='denoising', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=3200, batch_size=8, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3200, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=2, distributed_num_procs=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=2, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='bart_base', max_epoch=0, max_update=500000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[32], lr=[1e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='/home/dahmanir/lisa/Models/BART_10.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='lisa/Datasets/europarl_nl_bin', tokens_per_sample=512, sample_break_mode='complete_doc', mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=3.5, permute_sentences=1.0, mask_length='span-poisson', replace_length=1, shorten_method='none', shorten_data_split_list='', adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=500, force_anneal=None, end_learning_rate=0.0, power=1.0, total_num_update='500000', pad=1, eos=2, unk=3, dropout=0.1, attention_dropout=0.1, no_seed_provided=False, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layers=6, encoder_attention_heads=12, decoder_layers=6, decoder_attention_heads=12, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=True, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=3072, decoder_normalize_before=False, decoder_learned_pos=True, relu_dropout=0.0, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=768, decoder_input_dim=768, no_scale_embedding=True, layernorm_embedding=True, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='denoising', shuffle_instance=False, path='lisa/Models/BART_10_finetune.pt'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-07-12 14:59:17 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 14:59:18 | INFO | fairseq.tasks.denoising | loaded 128258 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 14:59:18 | INFO | fairseq.tasks.denoising | Split: valid, Loaded 128258 samples of denoising_dataset
2022-07-12 14:59:19 | WARNING | fairseq.tasks.fairseq_task | 2 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[109959, 112771]
2022-07-12 14:59:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 16032 loss=3303.739501953125, ntokens=3287, nsentences=8, sample_size=3287
2022-07-12 14:59:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 16032 loss=3270.851318359375, ntokens=3379, nsentences=8, sample_size=3379
2022-07-12 15:00:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 16032 loss=3245.6513671875, ntokens=3431, nsentences=8, sample_size=3431
2022-07-12 15:00:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 16032 loss=3565.7255859375, ntokens=3483, nsentences=8, sample_size=3483
2022-07-12 15:00:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 16032 loss=2927.192138671875, ntokens=3508, nsentences=8, sample_size=3508
2022-07-12 15:01:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 16032 loss=3073.189208984375, ntokens=3522, nsentences=8, sample_size=3522
2022-07-12 15:01:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 16032 loss=3386.168212890625, ntokens=3534, nsentences=8, sample_size=3534
2022-07-12 15:01:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 16032 loss=3497.1953125, ntokens=3528, nsentences=8, sample_size=3528
2022-07-12 15:01:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 16032 loss=3384.43798828125, ntokens=3573, nsentences=8, sample_size=3573
2022-07-12 15:02:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 16032 loss=3389.459716796875, ntokens=3573, nsentences=8, sample_size=3573
2022-07-12 15:02:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 16032 loss=3264.3076171875, ntokens=3592, nsentences=8, sample_size=3592
2022-07-12 15:02:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 16032 loss=3552.508544921875, ntokens=3614, nsentences=8, sample_size=3614
2022-07-12 15:03:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 16032 loss=3310.820068359375, ntokens=3596, nsentences=8, sample_size=3596
2022-07-12 15:03:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 16032 loss=3344.715576171875, ntokens=3631, nsentences=8, sample_size=3631
2022-07-12 15:03:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 16032 loss=3292.99072265625, ntokens=3645, nsentences=8, sample_size=3645
2022-07-12 15:03:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 16032 loss=3440.749267578125, ntokens=3665, nsentences=8, sample_size=3665
2022-07-12 15:04:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 16032 loss=3451.0517578125, ntokens=3658, nsentences=8, sample_size=3658
2022-07-12 15:04:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 16032 loss=3379.822509765625, ntokens=3638, nsentences=8, sample_size=3638
2022-07-12 15:04:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 16032 loss=3222.84619140625, ntokens=3651, nsentences=8, sample_size=3651
2022-07-12 15:05:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 16032 loss=3337.97900390625, ntokens=3660, nsentences=8, sample_size=3660
2022-07-12 15:05:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 16032 loss=3542.52880859375, ntokens=3659, nsentences=8, sample_size=3659
2022-07-12 15:05:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 16032 loss=3484.3505859375, ntokens=3656, nsentences=8, sample_size=3656
2022-07-12 15:06:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 16032 loss=3626.283447265625, ntokens=3681, nsentences=8, sample_size=3681
2022-07-12 15:06:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 16032 loss=3323.718994140625, ntokens=3702, nsentences=8, sample_size=3702
2022-07-12 15:06:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 16032 loss=3440.2431640625, ntokens=3691, nsentences=8, sample_size=3691
2022-07-12 15:07:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 16032 loss=3437.327392578125, ntokens=3688, nsentences=8, sample_size=3688
2022-07-12 15:07:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 16032 loss=3546.183349609375, ntokens=3698, nsentences=8, sample_size=3698
2022-07-12 15:07:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 16032 loss=3564.998779296875, ntokens=3697, nsentences=8, sample_size=3697
2022-07-12 15:07:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 16032 loss=3421.179931640625, ntokens=3714, nsentences=8, sample_size=3714
2022-07-12 15:08:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 16032 loss=3513.37646484375, ntokens=3699, nsentences=8, sample_size=3699
2022-07-12 15:08:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 16032 loss=3273.47314453125, ntokens=3717, nsentences=8, sample_size=3717
2022-07-12 15:08:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 16032 loss=3511.7705078125, ntokens=3716, nsentences=8, sample_size=3716
2022-07-12 15:09:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 16032 loss=3591.97412109375, ntokens=3715, nsentences=8, sample_size=3715
2022-07-12 15:09:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 16032 loss=3534.1142578125, ntokens=3720, nsentences=8, sample_size=3720
2022-07-12 15:09:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 16032 loss=3286.4326171875, ntokens=3735, nsentences=8, sample_size=3735
2022-07-12 15:10:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 16032 loss=3642.510009765625, ntokens=3719, nsentences=8, sample_size=3719
2022-07-12 15:10:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 16032 loss=3635.48046875, ntokens=3730, nsentences=8, sample_size=3730
2022-07-12 15:10:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 16032 loss=3812.758544921875, ntokens=3742, nsentences=8, sample_size=3742
2022-07-12 15:10:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 16032 loss=3728.20361328125, ntokens=3756, nsentences=8, sample_size=3756
2022-07-12 15:11:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 16032 loss=3249.388671875, ntokens=3751, nsentences=8, sample_size=3751
2022-07-12 15:11:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 16032 loss=3518.257568359375, ntokens=3759, nsentences=8, sample_size=3759
2022-07-12 15:11:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 16032 loss=3638.331298828125, ntokens=3742, nsentences=8, sample_size=3742
2022-07-12 15:12:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 16032 loss=3531.78466796875, ntokens=3745, nsentences=8, sample_size=3745
2022-07-12 15:12:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 16032 loss=3511.741455078125, ntokens=3760, nsentences=8, sample_size=3760
2022-07-12 15:12:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 16032 loss=3010.789306640625, ntokens=3762, nsentences=8, sample_size=3762
2022-07-12 15:13:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 16032 loss=3582.483154296875, ntokens=3763, nsentences=8, sample_size=3763
2022-07-12 15:13:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 16032 loss=3503.111572265625, ntokens=3773, nsentences=8, sample_size=3773
2022-07-12 15:13:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 16032 loss=3759.01416015625, ntokens=3766, nsentences=8, sample_size=3766
2022-07-12 15:14:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 16032 loss=3656.709716796875, ntokens=3756, nsentences=8, sample_size=3756
2022-07-12 15:14:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 16032 loss=3328.189208984375, ntokens=3771, nsentences=8, sample_size=3771
2022-07-12 15:14:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 16032 loss=3483.2626953125, ntokens=3772, nsentences=8, sample_size=3772
2022-07-12 15:14:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 16032 loss=3677.07958984375, ntokens=3765, nsentences=8, sample_size=3765
2022-07-12 15:15:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 16032 loss=3505.950927734375, ntokens=3784, nsentences=8, sample_size=3784
2022-07-12 15:15:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 16032 loss=3771.855224609375, ntokens=3776, nsentences=8, sample_size=3776
2022-07-12 15:15:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 16032 loss=3473.091552734375, ntokens=3775, nsentences=8, sample_size=3775
2022-07-12 15:16:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 16032 loss=3580.894775390625, ntokens=3762, nsentences=8, sample_size=3762
2022-07-12 15:16:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 16032 loss=3757.99365234375, ntokens=3787, nsentences=8, sample_size=3787
2022-07-12 15:16:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 16032 loss=3359.5419921875, ntokens=3816, nsentences=8, sample_size=3816
2022-07-12 15:17:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 16032 loss=3792.30517578125, ntokens=3810, nsentences=8, sample_size=3810
2022-07-12 15:17:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 16032 loss=3674.0693359375, ntokens=3793, nsentences=8, sample_size=3793
2022-07-12 15:17:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 16032 loss=3610.314697265625, ntokens=3802, nsentences=8, sample_size=3802
2022-07-12 15:18:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 16032 loss=3491.333740234375, ntokens=3796, nsentences=8, sample_size=3796
2022-07-12 15:18:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 16032 loss=3445.068603515625, ntokens=3798, nsentences=8, sample_size=3798
2022-07-12 15:18:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 16032 loss=3702.00146484375, ntokens=3804, nsentences=8, sample_size=3804
2022-07-12 15:19:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 16032 loss=3732.635498046875, ntokens=3825, nsentences=8, sample_size=3825
2022-07-12 15:19:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 16032 loss=3360.747802734375, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 15:19:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 16032 loss=3545.03564453125, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 15:20:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 16032 loss=3632.286376953125, ntokens=3823, nsentences=8, sample_size=3823
2022-07-12 15:20:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 16032 loss=3876.855224609375, ntokens=3813, nsentences=8, sample_size=3813
2022-07-12 15:20:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 16032 loss=3352.2451171875, ntokens=3837, nsentences=8, sample_size=3837
2022-07-12 15:21:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 16032 loss=3735.76220703125, ntokens=3798, nsentences=8, sample_size=3798
2022-07-12 15:21:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 16032 loss=3610.9521484375, ntokens=3832, nsentences=8, sample_size=3832
2022-07-12 15:21:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 16032 loss=3774.9814453125, ntokens=3810, nsentences=8, sample_size=3810
2022-07-12 15:22:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 16032 loss=3310.199951171875, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 15:22:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 16032 loss=3836.994873046875, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 15:22:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 16032 loss=3655.092041015625, ntokens=3844, nsentences=8, sample_size=3844
2022-07-12 15:22:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 16032 loss=3530.587890625, ntokens=3822, nsentences=8, sample_size=3822
2022-07-12 15:23:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 16032 loss=3561.03662109375, ntokens=3835, nsentences=8, sample_size=3835
2022-07-12 15:23:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 16032 loss=3684.211181640625, ntokens=3833, nsentences=8, sample_size=3833
2022-07-12 15:23:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 16032 loss=3804.857421875, ntokens=3821, nsentences=8, sample_size=3821
2022-07-12 15:24:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 16032 loss=3641.879638671875, ntokens=3842, nsentences=8, sample_size=3842
2022-07-12 15:24:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 16032 loss=3291.83447265625, ntokens=3855, nsentences=8, sample_size=3855
2022-07-12 15:24:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 16032 loss=3657.449462890625, ntokens=3831, nsentences=8, sample_size=3831
2022-07-12 15:25:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 16032 loss=3377.747314453125, ntokens=3862, nsentences=8, sample_size=3862
2022-07-12 15:25:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 16032 loss=3423.189208984375, ntokens=3837, nsentences=8, sample_size=3837
2022-07-12 15:25:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 16032 loss=3189.42724609375, ntokens=3850, nsentences=8, sample_size=3850
2022-07-12 15:26:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 16032 loss=3893.373046875, ntokens=3842, nsentences=8, sample_size=3842
2022-07-12 15:26:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 16032 loss=3685.302001953125, ntokens=3857, nsentences=8, sample_size=3857
2022-07-12 15:26:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 16032 loss=3819.32568359375, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 15:27:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 16032 loss=3576.21337890625, ntokens=3866, nsentences=8, sample_size=3866
2022-07-12 15:27:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 16032 loss=3816.2822265625, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 15:27:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 16032 loss=3713.777587890625, ntokens=3860, nsentences=8, sample_size=3860
2022-07-12 15:28:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 16032 loss=3627.735107421875, ntokens=3876, nsentences=8, sample_size=3876
2022-07-12 15:28:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 16032 loss=3638.092041015625, ntokens=3865, nsentences=8, sample_size=3865
2022-07-12 15:28:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 16032 loss=3453.251708984375, ntokens=3860, nsentences=8, sample_size=3860
2022-07-12 15:29:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 16032 loss=3707.212646484375, ntokens=3878, nsentences=8, sample_size=3878
2022-07-12 15:29:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 16032 loss=3664.822998046875, ntokens=3875, nsentences=8, sample_size=3875
2022-07-12 15:29:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 16032 loss=3337.8701171875, ntokens=3872, nsentences=8, sample_size=3872
2022-07-12 15:30:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 16032 loss=3270.62109375, ntokens=3874, nsentences=8, sample_size=3874
2022-07-12 15:30:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 16032 loss=3692.1787109375, ntokens=3868, nsentences=8, sample_size=3868
2022-07-12 15:30:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 16032 loss=3720.68115234375, ntokens=3875, nsentences=8, sample_size=3875
2022-07-12 15:31:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 16032 loss=3478.906494140625, ntokens=3893, nsentences=8, sample_size=3893
2022-07-12 15:31:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 16032 loss=3327.67919921875, ntokens=3868, nsentences=8, sample_size=3868
2022-07-12 15:31:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 16032 loss=3294.181884765625, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 15:32:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 16032 loss=3544.859375, ntokens=3886, nsentences=8, sample_size=3886
2022-07-12 15:32:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 16032 loss=3687.127197265625, ntokens=3884, nsentences=8, sample_size=3884
2022-07-12 15:32:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 16032 loss=3586.338134765625, ntokens=3890, nsentences=8, sample_size=3890
2022-07-12 15:33:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 16032 loss=3517.05078125, ntokens=3897, nsentences=8, sample_size=3897
2022-07-12 15:33:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 16032 loss=3823.16455078125, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 15:33:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 16032 loss=3480.92431640625, ntokens=3889, nsentences=8, sample_size=3889
2022-07-12 15:34:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 16032 loss=3780.542236328125, ntokens=3888, nsentences=8, sample_size=3888
2022-07-12 15:34:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 16032 loss=3214.596923828125, ntokens=3891, nsentences=8, sample_size=3891
2022-07-12 15:34:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 16032 loss=3520.369384765625, ntokens=3911, nsentences=8, sample_size=3911
2022-07-12 15:35:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 16032 loss=3912.110107421875, ntokens=3881, nsentences=8, sample_size=3881
2022-07-12 15:35:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 16032 loss=3711.593994140625, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 15:35:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 16032 loss=3762.67138671875, ntokens=3902, nsentences=8, sample_size=3902
2022-07-12 15:36:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 16032 loss=3702.38818359375, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 15:36:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 16032 loss=3550.39990234375, ntokens=3916, nsentences=8, sample_size=3916
2022-07-12 15:36:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 16032 loss=3695.56689453125, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 15:37:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 16032 loss=3521.75341796875, ntokens=3897, nsentences=8, sample_size=3897
2022-07-12 15:37:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 16032 loss=3713.76318359375, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 15:37:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 16032 loss=3642.37744140625, ntokens=3920, nsentences=8, sample_size=3920
2022-07-12 15:38:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 16032 loss=3493.063720703125, ntokens=3910, nsentences=8, sample_size=3910
2022-07-12 15:38:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 16032 loss=3886.426513671875, ntokens=3892, nsentences=8, sample_size=3892
2022-07-12 15:38:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 16032 loss=3591.6142578125, ntokens=3923, nsentences=8, sample_size=3923
2022-07-12 15:39:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 16032 loss=3758.5654296875, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 15:39:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 16032 loss=3563.688720703125, ntokens=3920, nsentences=8, sample_size=3920
2022-07-12 15:39:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 16032 loss=3602.861083984375, ntokens=3932, nsentences=8, sample_size=3932
2022-07-12 15:40:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 16032 loss=3759.88232421875, ntokens=3902, nsentences=8, sample_size=3902
2022-07-12 15:40:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 16032 loss=3558.71240234375, ntokens=3926, nsentences=8, sample_size=3926
2022-07-12 15:40:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 16032 loss=3858.5380859375, ntokens=3933, nsentences=8, sample_size=3933
2022-07-12 15:41:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 16032 loss=3638.248046875, ntokens=3933, nsentences=8, sample_size=3933
2022-07-12 15:41:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 16032 loss=3629.975830078125, ntokens=3925, nsentences=8, sample_size=3925
2022-07-12 15:41:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 16032 loss=3969.333740234375, ntokens=3939, nsentences=8, sample_size=3939
2022-07-12 15:42:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 16032 loss=3942.16015625, ntokens=3924, nsentences=8, sample_size=3924
2022-07-12 15:42:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 16032 loss=3712.659912109375, ntokens=3936, nsentences=8, sample_size=3936
2022-07-12 15:42:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 16032 loss=3818.8681640625, ntokens=3958, nsentences=8, sample_size=3958
2022-07-12 15:43:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 16032 loss=3574.890869140625, ntokens=3918, nsentences=8, sample_size=3918
2022-07-12 15:43:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 16032 loss=3734.7021484375, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 15:43:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 16032 loss=3811.19775390625, ntokens=3919, nsentences=8, sample_size=3919
2022-07-12 15:44:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 16032 loss=3726.804443359375, ntokens=3945, nsentences=8, sample_size=3945
2022-07-12 15:44:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 16032 loss=3739.12744140625, ntokens=3945, nsentences=8, sample_size=3945
2022-07-12 15:44:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 16032 loss=3214.362060546875, ntokens=3938, nsentences=8, sample_size=3938
2022-07-12 15:45:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 16032 loss=4153.38916015625, ntokens=3942, nsentences=8, sample_size=3942
2022-07-12 15:45:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 16032 loss=3684.177490234375, ntokens=3938, nsentences=8, sample_size=3938
2022-07-12 15:45:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 16032 loss=3731.913818359375, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 15:46:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 16032 loss=3690.344970703125, ntokens=3952, nsentences=8, sample_size=3952
2022-07-12 15:46:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 16032 loss=3691.330078125, ntokens=3960, nsentences=8, sample_size=3960
2022-07-12 15:46:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 16032 loss=3849.27783203125, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 15:47:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 16032 loss=3736.8134765625, ntokens=3930, nsentences=8, sample_size=3930
2022-07-12 15:47:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 16032 loss=3501.480224609375, ntokens=3942, nsentences=8, sample_size=3942
2022-07-12 15:47:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 16032 loss=3839.6484375, ntokens=3962, nsentences=8, sample_size=3962
2022-07-12 15:48:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 16032 loss=3725.534423828125, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 15:48:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 16032 loss=3525.797607421875, ntokens=3958, nsentences=8, sample_size=3958
2022-07-12 15:48:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 16032 loss=3796.79736328125, ntokens=3960, nsentences=8, sample_size=3960
2022-07-12 15:49:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 16032 loss=3632.469482421875, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 15:49:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 16032 loss=3817.4873046875, ntokens=3979, nsentences=8, sample_size=3979
2022-07-12 15:49:47 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 16032 loss=3556.16748046875, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 15:50:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 16032 loss=3539.490234375, ntokens=3952, nsentences=8, sample_size=3952
2022-07-12 15:50:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  16001 / 16032 loss=3925.27734375, ntokens=3970, nsentences=8, sample_size=3970
2022-07-12 15:50:33 | INFO | valid | valid on 'valid' subset | loss 1.344 | ppl 2.54 | wps 0 | wpb 6.10422e+07 | bsz 128256
2022-07-12 15:50:40 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/BART_25_finetune.pt
2022-07-12 15:50:44 | INFO | fairseq.tasks.denoising | dictionary: 39984 types
2022-07-12 15:50:55 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'BART', 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/BART_25_finetune.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12485', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 3200, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/dahmanir/lisa/Models/BART_25.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=200, log_format='json', log_file=None, tensorboard_logdir=None, wandb_project='BART', azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='denoising', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=3200, batch_size=8, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3200, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=2, distributed_num_procs=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=2, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='bart_base', max_epoch=0, max_update=500000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[32], lr=[1e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='/home/dahmanir/lisa/Models/BART_25.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='lisa/Datasets/europarl_nl_bin', tokens_per_sample=512, sample_break_mode='complete_doc', mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=3.5, permute_sentences=1.0, mask_length='span-poisson', replace_length=1, shorten_method='none', shorten_data_split_list='', adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=500, force_anneal=None, end_learning_rate=0.0, power=1.0, total_num_update='500000', pad=1, eos=2, unk=3, dropout=0.1, attention_dropout=0.1, no_seed_provided=False, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layers=6, encoder_attention_heads=12, decoder_layers=6, decoder_attention_heads=12, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=True, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=3072, decoder_normalize_before=False, decoder_learned_pos=True, relu_dropout=0.0, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=768, decoder_input_dim=768, no_scale_embedding=True, layernorm_embedding=True, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='bart_base', activation_dropout=0.0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, path='lisa/Models/BART_25_finetune.pt'), 'task': Namespace(no_progress_bar=False, log_interval=200, log_format='json', log_file=None, tensorboard_logdir=None, wandb_project='BART', azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='denoising', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=3200, batch_size=8, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3200, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=2, distributed_num_procs=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=2, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='bart_base', max_epoch=0, max_update=500000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[32], lr=[1e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='/home/dahmanir/lisa/Models/BART_25.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='lisa/Datasets/europarl_nl_bin', tokens_per_sample=512, sample_break_mode='complete_doc', mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=3.5, permute_sentences=1.0, mask_length='span-poisson', replace_length=1, shorten_method='none', shorten_data_split_list='', adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=500, force_anneal=None, end_learning_rate=0.0, power=1.0, total_num_update='500000', pad=1, eos=2, unk=3, dropout=0.1, attention_dropout=0.1, no_seed_provided=False, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layers=6, encoder_attention_heads=12, decoder_layers=6, decoder_attention_heads=12, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=True, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=3072, decoder_normalize_before=False, decoder_learned_pos=True, relu_dropout=0.0, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=768, decoder_input_dim=768, no_scale_embedding=True, layernorm_embedding=True, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='denoising', shuffle_instance=False, path='lisa/Models/BART_25_finetune.pt'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-07-12 15:50:55 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 15:50:55 | INFO | fairseq.tasks.denoising | loaded 128258 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 15:50:55 | INFO | fairseq.tasks.denoising | Split: valid, Loaded 128258 samples of denoising_dataset
2022-07-12 15:50:56 | WARNING | fairseq.tasks.fairseq_task | 2 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[109959, 112771]
2022-07-12 15:51:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 16032 loss=3194.68212890625, ntokens=3287, nsentences=8, sample_size=3287
2022-07-12 15:51:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 16032 loss=3299.481201171875, ntokens=3379, nsentences=8, sample_size=3379
2022-07-12 15:51:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 16032 loss=3354.074462890625, ntokens=3431, nsentences=8, sample_size=3431
2022-07-12 15:52:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 16032 loss=3333.508056640625, ntokens=3483, nsentences=8, sample_size=3483
2022-07-12 15:52:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 16032 loss=2881.660888671875, ntokens=3508, nsentences=8, sample_size=3508
2022-07-12 15:52:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 16032 loss=3106.91015625, ntokens=3522, nsentences=8, sample_size=3522
2022-07-12 15:52:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 16032 loss=3332.9140625, ntokens=3534, nsentences=8, sample_size=3534
2022-07-12 15:53:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 16032 loss=3370.58837890625, ntokens=3528, nsentences=8, sample_size=3528
2022-07-12 15:53:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 16032 loss=3198.49755859375, ntokens=3573, nsentences=8, sample_size=3573
2022-07-12 15:53:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 16032 loss=3510.495361328125, ntokens=3573, nsentences=8, sample_size=3573
2022-07-12 15:54:06 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 16032 loss=3465.84423828125, ntokens=3592, nsentences=8, sample_size=3592
2022-07-12 15:54:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 16032 loss=3426.459716796875, ntokens=3614, nsentences=8, sample_size=3614
2022-07-12 15:54:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 16032 loss=3415.84619140625, ntokens=3596, nsentences=8, sample_size=3596
2022-07-12 15:55:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 16032 loss=3176.674072265625, ntokens=3631, nsentences=8, sample_size=3631
2022-07-12 15:55:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 16032 loss=3346.25439453125, ntokens=3645, nsentences=8, sample_size=3645
2022-07-12 15:55:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 16032 loss=3420.754150390625, ntokens=3665, nsentences=8, sample_size=3665
2022-07-12 15:55:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 16032 loss=3560.93212890625, ntokens=3658, nsentences=8, sample_size=3658
2022-07-12 15:56:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 16032 loss=3461.430419921875, ntokens=3638, nsentences=8, sample_size=3638
2022-07-12 15:56:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 16032 loss=3446.4921875, ntokens=3651, nsentences=8, sample_size=3651
2022-07-12 15:56:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 16032 loss=3075.44189453125, ntokens=3660, nsentences=8, sample_size=3660
2022-07-12 15:57:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 16032 loss=3308.036865234375, ntokens=3659, nsentences=8, sample_size=3659
2022-07-12 15:57:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 16032 loss=3558.60888671875, ntokens=3656, nsentences=8, sample_size=3656
2022-07-12 15:57:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 16032 loss=3556.345458984375, ntokens=3681, nsentences=8, sample_size=3681
2022-07-12 15:58:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 16032 loss=3392.029541015625, ntokens=3702, nsentences=8, sample_size=3702
2022-07-12 15:58:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 16032 loss=3276.694091796875, ntokens=3691, nsentences=8, sample_size=3691
2022-07-12 15:58:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 16032 loss=3251.07470703125, ntokens=3688, nsentences=8, sample_size=3688
2022-07-12 15:58:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 16032 loss=3324.638427734375, ntokens=3698, nsentences=8, sample_size=3698
2022-07-12 15:59:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 16032 loss=3775.3359375, ntokens=3697, nsentences=8, sample_size=3697
2022-07-12 15:59:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 16032 loss=3452.563720703125, ntokens=3714, nsentences=8, sample_size=3714
2022-07-12 15:59:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 16032 loss=3373.727294921875, ntokens=3699, nsentences=8, sample_size=3699
2022-07-12 16:00:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 16032 loss=3184.076904296875, ntokens=3717, nsentences=8, sample_size=3717
2022-07-12 16:00:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 16032 loss=3307.24951171875, ntokens=3716, nsentences=8, sample_size=3716
2022-07-12 16:00:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 16032 loss=3550.4453125, ntokens=3715, nsentences=8, sample_size=3715
2022-07-12 16:01:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 16032 loss=3599.36572265625, ntokens=3720, nsentences=8, sample_size=3720
2022-07-12 16:01:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 16032 loss=3434.53564453125, ntokens=3735, nsentences=8, sample_size=3735
2022-07-12 16:01:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 16032 loss=3771.14013671875, ntokens=3719, nsentences=8, sample_size=3719
2022-07-12 16:02:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 16032 loss=3647.211181640625, ntokens=3730, nsentences=8, sample_size=3730
2022-07-12 16:02:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 16032 loss=3549.144775390625, ntokens=3742, nsentences=8, sample_size=3742
2022-07-12 16:02:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 16032 loss=3757.817626953125, ntokens=3756, nsentences=8, sample_size=3756
2022-07-12 16:02:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 16032 loss=3328.74560546875, ntokens=3751, nsentences=8, sample_size=3751
2022-07-12 16:03:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 16032 loss=3363.7158203125, ntokens=3759, nsentences=8, sample_size=3759
2022-07-12 16:03:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 16032 loss=3504.197265625, ntokens=3742, nsentences=8, sample_size=3742
2022-07-12 16:03:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 16032 loss=3687.4140625, ntokens=3745, nsentences=8, sample_size=3745
2022-07-12 16:04:09 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 16032 loss=3390.1181640625, ntokens=3760, nsentences=8, sample_size=3760
2022-07-12 16:04:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 16032 loss=3275.74755859375, ntokens=3762, nsentences=8, sample_size=3762
2022-07-12 16:04:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 16032 loss=3499.374267578125, ntokens=3763, nsentences=8, sample_size=3763
2022-07-12 16:05:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 16032 loss=3564.85009765625, ntokens=3773, nsentences=8, sample_size=3773
2022-07-12 16:05:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 16032 loss=3679.5751953125, ntokens=3766, nsentences=8, sample_size=3766
2022-07-12 16:05:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 16032 loss=3727.12451171875, ntokens=3756, nsentences=8, sample_size=3756
2022-07-12 16:06:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 16032 loss=3289.715087890625, ntokens=3771, nsentences=8, sample_size=3771
2022-07-12 16:06:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 16032 loss=3562.623779296875, ntokens=3772, nsentences=8, sample_size=3772
2022-07-12 16:06:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 16032 loss=3606.925048828125, ntokens=3765, nsentences=8, sample_size=3765
2022-07-12 16:06:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 16032 loss=3572.7978515625, ntokens=3784, nsentences=8, sample_size=3784
2022-07-12 16:07:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 16032 loss=3653.739013671875, ntokens=3776, nsentences=8, sample_size=3776
2022-07-12 16:07:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 16032 loss=3562.16552734375, ntokens=3775, nsentences=8, sample_size=3775
2022-07-12 16:07:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 16032 loss=3412.67578125, ntokens=3762, nsentences=8, sample_size=3762
2022-07-12 16:08:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 16032 loss=3613.234375, ntokens=3787, nsentences=8, sample_size=3787
2022-07-12 16:08:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 16032 loss=3459.103271484375, ntokens=3816, nsentences=8, sample_size=3816
2022-07-12 16:08:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 16032 loss=3779.619140625, ntokens=3810, nsentences=8, sample_size=3810
2022-07-12 16:09:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 16032 loss=3795.259033203125, ntokens=3793, nsentences=8, sample_size=3793
2022-07-12 16:09:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 16032 loss=3343.531982421875, ntokens=3802, nsentences=8, sample_size=3802
2022-07-12 16:09:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 16032 loss=3408.950927734375, ntokens=3796, nsentences=8, sample_size=3796
2022-07-12 16:10:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 16032 loss=3505.1142578125, ntokens=3798, nsentences=8, sample_size=3798
2022-07-12 16:10:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 16032 loss=3735.67578125, ntokens=3804, nsentences=8, sample_size=3804
2022-07-12 16:10:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 16032 loss=3723.495849609375, ntokens=3825, nsentences=8, sample_size=3825
2022-07-12 16:11:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 16032 loss=3269.91015625, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 16:11:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 16032 loss=3932.77587890625, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 16:11:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 16032 loss=3552.169189453125, ntokens=3823, nsentences=8, sample_size=3823
2022-07-12 16:12:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 16032 loss=3617.8203125, ntokens=3813, nsentences=8, sample_size=3813
2022-07-12 16:12:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 16032 loss=3188.41015625, ntokens=3837, nsentences=8, sample_size=3837
2022-07-12 16:12:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 16032 loss=3482.781494140625, ntokens=3798, nsentences=8, sample_size=3798
2022-07-12 16:13:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 16032 loss=3734.2841796875, ntokens=3832, nsentences=8, sample_size=3832
2022-07-12 16:13:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 16032 loss=3544.30419921875, ntokens=3810, nsentences=8, sample_size=3810
2022-07-12 16:13:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 16032 loss=3147.9580078125, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 16:14:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 16032 loss=3809.994140625, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 16:14:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 16032 loss=3725.319091796875, ntokens=3844, nsentences=8, sample_size=3844
2022-07-12 16:14:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 16032 loss=3610.252197265625, ntokens=3822, nsentences=8, sample_size=3822
2022-07-12 16:15:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 16032 loss=3590.074951171875, ntokens=3835, nsentences=8, sample_size=3835
2022-07-12 16:15:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 16032 loss=3781.6298828125, ntokens=3833, nsentences=8, sample_size=3833
2022-07-12 16:15:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 16032 loss=3664.76416015625, ntokens=3821, nsentences=8, sample_size=3821
2022-07-12 16:15:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 16032 loss=3546.07958984375, ntokens=3842, nsentences=8, sample_size=3842
2022-07-12 16:16:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 16032 loss=3141.57275390625, ntokens=3855, nsentences=8, sample_size=3855
2022-07-12 16:16:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 16032 loss=3579.134765625, ntokens=3831, nsentences=8, sample_size=3831
2022-07-12 16:16:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 16032 loss=3338.577392578125, ntokens=3862, nsentences=8, sample_size=3862
2022-07-12 16:17:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 16032 loss=3492.095458984375, ntokens=3837, nsentences=8, sample_size=3837
2022-07-12 16:17:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 16032 loss=3136.89697265625, ntokens=3850, nsentences=8, sample_size=3850
2022-07-12 16:17:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 16032 loss=3872.343994140625, ntokens=3842, nsentences=8, sample_size=3842
2022-07-12 16:18:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 16032 loss=3547.7041015625, ntokens=3857, nsentences=8, sample_size=3857
2022-07-12 16:18:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 16032 loss=3755.012451171875, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 16:19:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 16032 loss=3300.723876953125, ntokens=3866, nsentences=8, sample_size=3866
2022-07-12 16:19:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 16032 loss=3802.868896484375, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 16:19:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 16032 loss=3683.899658203125, ntokens=3860, nsentences=8, sample_size=3860
2022-07-12 16:20:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 16032 loss=3490.84375, ntokens=3876, nsentences=8, sample_size=3876
2022-07-12 16:20:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 16032 loss=3475.38134765625, ntokens=3865, nsentences=8, sample_size=3865
2022-07-12 16:20:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 16032 loss=3480.121337890625, ntokens=3860, nsentences=8, sample_size=3860
2022-07-12 16:21:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 16032 loss=3390.34375, ntokens=3878, nsentences=8, sample_size=3878
2022-07-12 16:21:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 16032 loss=3699.278564453125, ntokens=3875, nsentences=8, sample_size=3875
2022-07-12 16:21:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 16032 loss=3346.28125, ntokens=3872, nsentences=8, sample_size=3872
2022-07-12 16:22:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 16032 loss=3543.41552734375, ntokens=3874, nsentences=8, sample_size=3874
2022-07-12 16:22:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 16032 loss=3707.105712890625, ntokens=3868, nsentences=8, sample_size=3868
2022-07-12 16:22:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 16032 loss=3788.513427734375, ntokens=3875, nsentences=8, sample_size=3875
2022-07-12 16:23:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 16032 loss=3406.797119140625, ntokens=3893, nsentences=8, sample_size=3893
2022-07-12 16:23:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 16032 loss=3428.02197265625, ntokens=3868, nsentences=8, sample_size=3868
2022-07-12 16:23:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 16032 loss=3268.101806640625, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 16:24:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 16032 loss=3642.964111328125, ntokens=3886, nsentences=8, sample_size=3886
2022-07-12 16:24:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 16032 loss=3808.553466796875, ntokens=3884, nsentences=8, sample_size=3884
2022-07-12 16:24:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 16032 loss=3434.83056640625, ntokens=3890, nsentences=8, sample_size=3890
2022-07-12 16:25:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 16032 loss=3443.619140625, ntokens=3897, nsentences=8, sample_size=3897
2022-07-12 16:25:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 16032 loss=3797.95263671875, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 16:25:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 16032 loss=3490.535888671875, ntokens=3889, nsentences=8, sample_size=3889
2022-07-12 16:26:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 16032 loss=3728.8076171875, ntokens=3888, nsentences=8, sample_size=3888
2022-07-12 16:26:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 16032 loss=3381.64453125, ntokens=3891, nsentences=8, sample_size=3891
2022-07-12 16:26:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 16032 loss=3593.903564453125, ntokens=3911, nsentences=8, sample_size=3911
2022-07-12 16:27:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 16032 loss=3919.541748046875, ntokens=3881, nsentences=8, sample_size=3881
2022-07-12 16:27:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 16032 loss=3463.380615234375, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 16:27:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 16032 loss=3896.899169921875, ntokens=3902, nsentences=8, sample_size=3902
2022-07-12 16:28:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 16032 loss=3569.864501953125, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 16:28:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 16032 loss=3557.1953125, ntokens=3916, nsentences=8, sample_size=3916
2022-07-12 16:28:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 16032 loss=3558.704833984375, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 16:29:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 16032 loss=3485.62890625, ntokens=3897, nsentences=8, sample_size=3897
2022-07-12 16:29:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 16032 loss=3525.134033203125, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 16:29:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 16032 loss=3820.20361328125, ntokens=3920, nsentences=8, sample_size=3920
2022-07-12 16:30:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 16032 loss=3457.6669921875, ntokens=3910, nsentences=8, sample_size=3910
2022-07-12 16:30:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 16032 loss=3859.609130859375, ntokens=3892, nsentences=8, sample_size=3892
2022-07-12 16:30:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 16032 loss=3736.222412109375, ntokens=3923, nsentences=8, sample_size=3923
2022-07-12 16:31:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 16032 loss=3702.572509765625, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 16:31:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 16032 loss=3546.174072265625, ntokens=3920, nsentences=8, sample_size=3920
2022-07-12 16:31:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 16032 loss=3631.721923828125, ntokens=3932, nsentences=8, sample_size=3932
2022-07-12 16:32:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 16032 loss=3569.271728515625, ntokens=3902, nsentences=8, sample_size=3902
2022-07-12 16:32:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 16032 loss=3568.834228515625, ntokens=3926, nsentences=8, sample_size=3926
2022-07-12 16:32:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 16032 loss=3496.04345703125, ntokens=3933, nsentences=8, sample_size=3933
2022-07-12 16:33:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 16032 loss=3745.10595703125, ntokens=3933, nsentences=8, sample_size=3933
2022-07-12 16:33:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 16032 loss=3790.766845703125, ntokens=3925, nsentences=8, sample_size=3925
2022-07-12 16:33:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 16032 loss=3943.997314453125, ntokens=3939, nsentences=8, sample_size=3939
2022-07-12 16:34:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 16032 loss=3461.793212890625, ntokens=3924, nsentences=8, sample_size=3924
2022-07-12 16:34:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 16032 loss=3786.246826171875, ntokens=3936, nsentences=8, sample_size=3936
2022-07-12 16:34:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 16032 loss=3738.2802734375, ntokens=3958, nsentences=8, sample_size=3958
2022-07-12 16:35:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 16032 loss=3610.8388671875, ntokens=3918, nsentences=8, sample_size=3918
2022-07-12 16:35:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 16032 loss=3719.3779296875, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 16:35:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 16032 loss=3767.55908203125, ntokens=3919, nsentences=8, sample_size=3919
2022-07-12 16:35:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 16032 loss=3740.167236328125, ntokens=3945, nsentences=8, sample_size=3945
2022-07-12 16:36:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 16032 loss=3569.606689453125, ntokens=3945, nsentences=8, sample_size=3945
2022-07-12 16:36:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 16032 loss=3562.45556640625, ntokens=3938, nsentences=8, sample_size=3938
2022-07-12 16:36:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 16032 loss=3841.210693359375, ntokens=3942, nsentences=8, sample_size=3942
2022-07-12 16:37:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 16032 loss=3710.267578125, ntokens=3938, nsentences=8, sample_size=3938
2022-07-12 16:37:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 16032 loss=3679.845703125, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 16:37:57 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 16032 loss=3809.43212890625, ntokens=3952, nsentences=8, sample_size=3952
2022-07-12 16:38:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 16032 loss=3631.58203125, ntokens=3960, nsentences=8, sample_size=3960
2022-07-12 16:38:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 16032 loss=3949.296630859375, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 16:38:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 16032 loss=3756.248046875, ntokens=3930, nsentences=8, sample_size=3930
2022-07-12 16:39:15 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 16032 loss=3776.870849609375, ntokens=3942, nsentences=8, sample_size=3942
2022-07-12 16:39:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 16032 loss=3999.042236328125, ntokens=3962, nsentences=8, sample_size=3962
2022-07-12 16:39:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 16032 loss=3784.330078125, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 16:40:13 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 16032 loss=3555.761962890625, ntokens=3958, nsentences=8, sample_size=3958
2022-07-12 16:40:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 16032 loss=3764.277587890625, ntokens=3960, nsentences=8, sample_size=3960
2022-07-12 16:40:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 16032 loss=3620.42431640625, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 16:41:11 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 16032 loss=3621.797607421875, ntokens=3979, nsentences=8, sample_size=3979
2022-07-12 16:41:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 16032 loss=3751.184814453125, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 16:41:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 16032 loss=3606.327880859375, ntokens=3952, nsentences=8, sample_size=3952
2022-07-12 16:42:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  16001 / 16032 loss=3637.8359375, ntokens=3970, nsentences=8, sample_size=3970
2022-07-12 16:42:16 | INFO | valid | valid on 'valid' subset | loss 1.34 | ppl 2.53 | wps 0 | wpb 6.10422e+07 | bsz 128256
2022-07-12 16:42:23 | INFO | fairseq_cli.validate | loading model(s) from lisa/Models/BART_50_finetune.pt
2022-07-12 16:42:29 | INFO | fairseq.tasks.denoising | dictionary: 39984 types
2022-07-12 16:42:41 | INFO | fairseq_cli.validate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'BART', 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'lisa/Models/BART_50_finetune.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11364', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 3200, 'batch_size': 8, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/dahmanir/lisa/Models/BART_50.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=200, log_format='json', log_file=None, tensorboard_logdir=None, wandb_project='BART', azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='denoising', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=3200, batch_size=8, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3200, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=2, distributed_num_procs=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=2, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='bart_base', max_epoch=0, max_update=500000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[32], lr=[1e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='/home/dahmanir/lisa/Models/BART_50.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='lisa/Datasets/europarl_nl_bin', tokens_per_sample=512, sample_break_mode='complete_doc', mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=3.5, permute_sentences=1.0, mask_length='span-poisson', replace_length=1, shorten_method='none', shorten_data_split_list='', adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=500, force_anneal=None, end_learning_rate=0.0, power=1.0, total_num_update='500000', pad=1, eos=2, unk=3, dropout=0.1, attention_dropout=0.1, no_seed_provided=False, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layers=6, encoder_attention_heads=12, decoder_layers=6, decoder_attention_heads=12, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=True, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=3072, decoder_normalize_before=False, decoder_learned_pos=True, relu_dropout=0.0, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=768, decoder_input_dim=768, no_scale_embedding=True, layernorm_embedding=True, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='bart_base', activation_dropout=0.0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, path='lisa/Models/BART_50_finetune.pt'), 'task': Namespace(no_progress_bar=False, log_interval=200, log_format='json', log_file=None, tensorboard_logdir=None, wandb_project='BART', azureml_logging=False, seed=4, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='polynomial_decay', simul_type=None, scoring='bleu', task='denoising', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=3200, batch_size=8, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3200, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=2, distributed_num_procs=2, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=2, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='bart_base', max_epoch=0, max_update=500000, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[32], lr=[1e-05], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints', restore_file='/home/dahmanir/lisa/Models/BART_50.pt', continue_once=None, finetune_from_model=None, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='lisa/Datasets/europarl_nl_bin', tokens_per_sample=512, sample_break_mode='complete_doc', mask=0.3, mask_random=0.1, insert=0.0, permute=0.0, rotate=0.0, poisson_lambda=3.5, permute_sentences=1.0, mask_length='span-poisson', replace_length=1, shorten_method='none', shorten_data_split_list='', adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.01, use_old_adam=False, fp16_adam_stats=False, warmup_updates=500, force_anneal=None, end_learning_rate=0.0, power=1.0, total_num_update='500000', pad=1, eos=2, unk=3, dropout=0.1, attention_dropout=0.1, no_seed_provided=False, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layers=6, encoder_attention_heads=12, decoder_layers=6, decoder_attention_heads=12, encoder_embed_path=None, encoder_normalize_before=False, encoder_learned_pos=True, decoder_embed_path=None, decoder_embed_dim=768, decoder_ffn_embed_dim=3072, decoder_normalize_before=False, decoder_learned_pos=True, relu_dropout=0.0, max_target_positions=1024, max_source_positions=1024, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=True, share_all_embeddings=True, decoder_output_dim=768, decoder_input_dim=768, no_scale_embedding=True, layernorm_embedding=True, activation_fn='gelu', pooler_activation_fn='tanh', pooler_dropout=0.0, _name='denoising', shuffle_instance=False, path='lisa/Models/BART_50_finetune.pt'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 500, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-07-12 16:42:41 | INFO | fairseq.data.data_utils | loaded 1,997,775 examples from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 16:42:41 | INFO | fairseq.tasks.denoising | loaded 128258 blocks from: lisa/Datasets/europarl_nl_bin/valid
2022-07-12 16:42:41 | INFO | fairseq.tasks.denoising | Split: valid, Loaded 128258 samples of denoising_dataset
2022-07-12 16:42:42 | WARNING | fairseq.tasks.fairseq_task | 2 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[109959, 112771]
2022-07-12 16:43:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    101 / 16032 loss=3209.810791015625, ntokens=3287, nsentences=8, sample_size=3287
2022-07-12 16:43:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    201 / 16032 loss=3389.34326171875, ntokens=3379, nsentences=8, sample_size=3379
2022-07-12 16:43:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    301 / 16032 loss=3063.10107421875, ntokens=3431, nsentences=8, sample_size=3431
2022-07-12 16:43:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    401 / 16032 loss=3557.939453125, ntokens=3483, nsentences=8, sample_size=3483
2022-07-12 16:44:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    501 / 16032 loss=2846.470703125, ntokens=3508, nsentences=8, sample_size=3508
2022-07-12 16:44:24 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    601 / 16032 loss=3126.53955078125, ntokens=3522, nsentences=8, sample_size=3522
2022-07-12 16:44:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    701 / 16032 loss=3488.102783203125, ntokens=3534, nsentences=8, sample_size=3534
2022-07-12 16:44:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    801 / 16032 loss=3606.4990234375, ntokens=3528, nsentences=8, sample_size=3528
2022-07-12 16:45:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:    901 / 16032 loss=3141.0634765625, ntokens=3573, nsentences=8, sample_size=3573
2022-07-12 16:45:34 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1001 / 16032 loss=3262.524169921875, ntokens=3573, nsentences=8, sample_size=3573
2022-07-12 16:45:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1101 / 16032 loss=3146.912353515625, ntokens=3592, nsentences=8, sample_size=3592
2022-07-12 16:46:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1201 / 16032 loss=3395.372802734375, ntokens=3614, nsentences=8, sample_size=3614
2022-07-12 16:46:28 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1301 / 16032 loss=3401.9228515625, ntokens=3596, nsentences=8, sample_size=3596
2022-07-12 16:46:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1401 / 16032 loss=3134.798828125, ntokens=3631, nsentences=8, sample_size=3631
2022-07-12 16:47:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1501 / 16032 loss=3238.823974609375, ntokens=3645, nsentences=8, sample_size=3645
2022-07-12 16:47:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1601 / 16032 loss=3577.046875, ntokens=3665, nsentences=8, sample_size=3665
2022-07-12 16:47:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1701 / 16032 loss=3443.2021484375, ntokens=3658, nsentences=8, sample_size=3658
2022-07-12 16:47:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1801 / 16032 loss=3630.95654296875, ntokens=3638, nsentences=8, sample_size=3638
2022-07-12 16:48:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   1901 / 16032 loss=3331.11328125, ntokens=3651, nsentences=8, sample_size=3651
2022-07-12 16:48:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2001 / 16032 loss=3234.981689453125, ntokens=3660, nsentences=8, sample_size=3660
2022-07-12 16:48:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2101 / 16032 loss=3265.88525390625, ntokens=3659, nsentences=8, sample_size=3659
2022-07-12 16:49:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2201 / 16032 loss=3456.19384765625, ntokens=3656, nsentences=8, sample_size=3656
2022-07-12 16:49:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2301 / 16032 loss=3575.846435546875, ntokens=3681, nsentences=8, sample_size=3681
2022-07-12 16:49:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2401 / 16032 loss=3177.561767578125, ntokens=3702, nsentences=8, sample_size=3702
2022-07-12 16:50:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2501 / 16032 loss=3297.322998046875, ntokens=3691, nsentences=8, sample_size=3691
2022-07-12 16:50:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2601 / 16032 loss=3158.64794921875, ntokens=3688, nsentences=8, sample_size=3688
2022-07-12 16:50:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2701 / 16032 loss=3310.045654296875, ntokens=3698, nsentences=8, sample_size=3698
2022-07-12 16:51:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2801 / 16032 loss=3595.33447265625, ntokens=3697, nsentences=8, sample_size=3697
2022-07-12 16:51:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   2901 / 16032 loss=3495.083740234375, ntokens=3714, nsentences=8, sample_size=3714
2022-07-12 16:51:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3001 / 16032 loss=3185.62646484375, ntokens=3699, nsentences=8, sample_size=3699
2022-07-12 16:51:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3101 / 16032 loss=3376.896728515625, ntokens=3717, nsentences=8, sample_size=3717
2022-07-12 16:52:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3201 / 16032 loss=3586.05224609375, ntokens=3716, nsentences=8, sample_size=3716
2022-07-12 16:52:32 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3301 / 16032 loss=3481.22216796875, ntokens=3715, nsentences=8, sample_size=3715
2022-07-12 16:52:50 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3401 / 16032 loss=3574.3212890625, ntokens=3720, nsentences=8, sample_size=3720
2022-07-12 16:53:08 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3501 / 16032 loss=3263.69775390625, ntokens=3735, nsentences=8, sample_size=3735
2022-07-12 16:53:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3601 / 16032 loss=3522.033203125, ntokens=3719, nsentences=8, sample_size=3719
2022-07-12 16:53:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3701 / 16032 loss=3636.70458984375, ntokens=3730, nsentences=8, sample_size=3730
2022-07-12 16:54:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3801 / 16032 loss=3610.8876953125, ntokens=3742, nsentences=8, sample_size=3742
2022-07-12 16:54:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   3901 / 16032 loss=3755.103515625, ntokens=3756, nsentences=8, sample_size=3756
2022-07-12 16:54:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4001 / 16032 loss=3224.42724609375, ntokens=3751, nsentences=8, sample_size=3751
2022-07-12 16:54:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4101 / 16032 loss=3325.27099609375, ntokens=3759, nsentences=8, sample_size=3759
2022-07-12 16:55:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4201 / 16032 loss=3556.415771484375, ntokens=3742, nsentences=8, sample_size=3742
2022-07-12 16:55:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4301 / 16032 loss=3468.270263671875, ntokens=3745, nsentences=8, sample_size=3745
2022-07-12 16:55:53 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4401 / 16032 loss=3478.759521484375, ntokens=3760, nsentences=8, sample_size=3760
2022-07-12 16:56:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4501 / 16032 loss=3109.1162109375, ntokens=3762, nsentences=8, sample_size=3762
2022-07-12 16:56:30 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4601 / 16032 loss=3603.9775390625, ntokens=3763, nsentences=8, sample_size=3763
2022-07-12 16:56:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4701 / 16032 loss=3351.66796875, ntokens=3773, nsentences=8, sample_size=3773
2022-07-12 16:57:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4801 / 16032 loss=3534.1005859375, ntokens=3766, nsentences=8, sample_size=3766
2022-07-12 16:57:26 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   4901 / 16032 loss=3653.872802734375, ntokens=3756, nsentences=8, sample_size=3756
2022-07-12 16:57:45 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5001 / 16032 loss=3302.12548828125, ntokens=3771, nsentences=8, sample_size=3771
2022-07-12 16:58:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5101 / 16032 loss=3697.2998046875, ntokens=3772, nsentences=8, sample_size=3772
2022-07-12 16:58:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5201 / 16032 loss=3640.95068359375, ntokens=3765, nsentences=8, sample_size=3765
2022-07-12 16:58:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5301 / 16032 loss=3612.5908203125, ntokens=3784, nsentences=8, sample_size=3784
2022-07-12 16:58:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5401 / 16032 loss=3796.94775390625, ntokens=3776, nsentences=8, sample_size=3776
2022-07-12 16:59:18 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5501 / 16032 loss=3677.196044921875, ntokens=3775, nsentences=8, sample_size=3775
2022-07-12 16:59:36 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5601 / 16032 loss=3502.99658203125, ntokens=3762, nsentences=8, sample_size=3762
2022-07-12 16:59:55 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5701 / 16032 loss=3460.37841796875, ntokens=3787, nsentences=8, sample_size=3787
2022-07-12 17:00:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5801 / 16032 loss=3579.063720703125, ntokens=3816, nsentences=8, sample_size=3816
2022-07-12 17:00:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   5901 / 16032 loss=3747.095703125, ntokens=3810, nsentences=8, sample_size=3810
2022-07-12 17:00:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6001 / 16032 loss=3779.35107421875, ntokens=3793, nsentences=8, sample_size=3793
2022-07-12 17:01:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6101 / 16032 loss=3568.36572265625, ntokens=3802, nsentences=8, sample_size=3802
2022-07-12 17:01:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6201 / 16032 loss=3600.700927734375, ntokens=3796, nsentences=8, sample_size=3796
2022-07-12 17:01:48 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6301 / 16032 loss=3417.28271484375, ntokens=3798, nsentences=8, sample_size=3798
2022-07-12 17:02:07 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6401 / 16032 loss=3795.621337890625, ntokens=3804, nsentences=8, sample_size=3804
2022-07-12 17:02:27 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6501 / 16032 loss=3693.05859375, ntokens=3825, nsentences=8, sample_size=3825
2022-07-12 17:02:46 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6601 / 16032 loss=3350.826171875, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 17:03:05 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6701 / 16032 loss=3745.617919921875, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 17:03:25 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6801 / 16032 loss=3506.440185546875, ntokens=3823, nsentences=8, sample_size=3823
2022-07-12 17:03:44 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   6901 / 16032 loss=3721.083251953125, ntokens=3813, nsentences=8, sample_size=3813
2022-07-12 17:04:04 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7001 / 16032 loss=3387.586181640625, ntokens=3837, nsentences=8, sample_size=3837
2022-07-12 17:04:23 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7101 / 16032 loss=3624.18359375, ntokens=3798, nsentences=8, sample_size=3798
2022-07-12 17:04:43 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7201 / 16032 loss=3540.235595703125, ntokens=3832, nsentences=8, sample_size=3832
2022-07-12 17:05:03 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7301 / 16032 loss=3545.53173828125, ntokens=3810, nsentences=8, sample_size=3810
2022-07-12 17:05:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7401 / 16032 loss=3378.474609375, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 17:05:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7501 / 16032 loss=3573.94580078125, ntokens=3807, nsentences=8, sample_size=3807
2022-07-12 17:06:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7601 / 16032 loss=3563.834716796875, ntokens=3844, nsentences=8, sample_size=3844
2022-07-12 17:06:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7701 / 16032 loss=3510.02099609375, ntokens=3822, nsentences=8, sample_size=3822
2022-07-12 17:06:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7801 / 16032 loss=3309.086181640625, ntokens=3835, nsentences=8, sample_size=3835
2022-07-12 17:07:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   7901 / 16032 loss=3594.916015625, ntokens=3833, nsentences=8, sample_size=3833
2022-07-12 17:07:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8001 / 16032 loss=3722.448486328125, ntokens=3821, nsentences=8, sample_size=3821
2022-07-12 17:07:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8101 / 16032 loss=3506.333984375, ntokens=3842, nsentences=8, sample_size=3842
2022-07-12 17:08:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8201 / 16032 loss=3450.419189453125, ntokens=3855, nsentences=8, sample_size=3855
2022-07-12 17:08:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8301 / 16032 loss=3662.805908203125, ntokens=3831, nsentences=8, sample_size=3831
2022-07-12 17:08:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8401 / 16032 loss=3385.61865234375, ntokens=3862, nsentences=8, sample_size=3862
2022-07-12 17:09:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8501 / 16032 loss=3471.103759765625, ntokens=3837, nsentences=8, sample_size=3837
2022-07-12 17:09:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8601 / 16032 loss=3463.633056640625, ntokens=3850, nsentences=8, sample_size=3850
2022-07-12 17:09:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8701 / 16032 loss=3657.87060546875, ntokens=3842, nsentences=8, sample_size=3842
2022-07-12 17:10:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8801 / 16032 loss=3857.406982421875, ntokens=3857, nsentences=8, sample_size=3857
2022-07-12 17:10:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   8901 / 16032 loss=3694.63623046875, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 17:10:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9001 / 16032 loss=3630.177978515625, ntokens=3866, nsentences=8, sample_size=3866
2022-07-12 17:11:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9101 / 16032 loss=3890.691650390625, ntokens=3852, nsentences=8, sample_size=3852
2022-07-12 17:11:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9201 / 16032 loss=3738.94580078125, ntokens=3860, nsentences=8, sample_size=3860
2022-07-12 17:11:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9301 / 16032 loss=3507.9853515625, ntokens=3876, nsentences=8, sample_size=3876
2022-07-12 17:12:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9401 / 16032 loss=3802.78564453125, ntokens=3865, nsentences=8, sample_size=3865
2022-07-12 17:12:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9501 / 16032 loss=3421.35302734375, ntokens=3860, nsentences=8, sample_size=3860
2022-07-12 17:12:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9601 / 16032 loss=3795.443603515625, ntokens=3878, nsentences=8, sample_size=3878
2022-07-12 17:13:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9701 / 16032 loss=3500.27587890625, ntokens=3875, nsentences=8, sample_size=3875
2022-07-12 17:13:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9801 / 16032 loss=3320.23974609375, ntokens=3872, nsentences=8, sample_size=3872
2022-07-12 17:13:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:   9901 / 16032 loss=3461.061279296875, ntokens=3874, nsentences=8, sample_size=3874
2022-07-12 17:14:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10001 / 16032 loss=3801.180908203125, ntokens=3868, nsentences=8, sample_size=3868
2022-07-12 17:14:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10101 / 16032 loss=3646.97314453125, ntokens=3875, nsentences=8, sample_size=3875
2022-07-12 17:14:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10201 / 16032 loss=3538.313720703125, ntokens=3893, nsentences=8, sample_size=3893
2022-07-12 17:15:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10301 / 16032 loss=3356.818115234375, ntokens=3868, nsentences=8, sample_size=3868
2022-07-12 17:15:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10401 / 16032 loss=3162.655517578125, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 17:15:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10501 / 16032 loss=3531.17431640625, ntokens=3886, nsentences=8, sample_size=3886
2022-07-12 17:16:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10601 / 16032 loss=3771.50927734375, ntokens=3884, nsentences=8, sample_size=3884
2022-07-12 17:16:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10701 / 16032 loss=3657.490234375, ntokens=3890, nsentences=8, sample_size=3890
2022-07-12 17:16:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10801 / 16032 loss=3436.150146484375, ntokens=3897, nsentences=8, sample_size=3897
2022-07-12 17:17:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  10901 / 16032 loss=3917.684326171875, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 17:17:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11001 / 16032 loss=3506.178955078125, ntokens=3889, nsentences=8, sample_size=3889
2022-07-12 17:17:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11101 / 16032 loss=3790.1591796875, ntokens=3888, nsentences=8, sample_size=3888
2022-07-12 17:18:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11201 / 16032 loss=3288.268798828125, ntokens=3891, nsentences=8, sample_size=3891
2022-07-12 17:18:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11301 / 16032 loss=3519.841796875, ntokens=3911, nsentences=8, sample_size=3911
2022-07-12 17:18:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11401 / 16032 loss=4099.119140625, ntokens=3881, nsentences=8, sample_size=3881
2022-07-12 17:19:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11501 / 16032 loss=3766.461669921875, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 17:19:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11601 / 16032 loss=3893.891357421875, ntokens=3902, nsentences=8, sample_size=3902
2022-07-12 17:19:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11701 / 16032 loss=3555.248291015625, ntokens=3894, nsentences=8, sample_size=3894
2022-07-12 17:20:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11801 / 16032 loss=3400.048583984375, ntokens=3916, nsentences=8, sample_size=3916
2022-07-12 17:20:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  11901 / 16032 loss=3692.9375, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 17:20:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12001 / 16032 loss=3578.583984375, ntokens=3897, nsentences=8, sample_size=3897
2022-07-12 17:21:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12101 / 16032 loss=3571.401611328125, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 17:21:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12201 / 16032 loss=3834.628662109375, ntokens=3920, nsentences=8, sample_size=3920
2022-07-12 17:21:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12301 / 16032 loss=3273.904541015625, ntokens=3910, nsentences=8, sample_size=3910
2022-07-12 17:22:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12401 / 16032 loss=3649.046142578125, ntokens=3892, nsentences=8, sample_size=3892
2022-07-12 17:22:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12501 / 16032 loss=3943.697509765625, ntokens=3923, nsentences=8, sample_size=3923
2022-07-12 17:22:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12601 / 16032 loss=3573.467041015625, ntokens=3906, nsentences=8, sample_size=3906
2022-07-12 17:23:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12701 / 16032 loss=3758.27587890625, ntokens=3920, nsentences=8, sample_size=3920
2022-07-12 17:23:22 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12801 / 16032 loss=3543.97265625, ntokens=3932, nsentences=8, sample_size=3932
2022-07-12 17:23:42 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  12901 / 16032 loss=4048.80419921875, ntokens=3902, nsentences=8, sample_size=3902
2022-07-12 17:24:02 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13001 / 16032 loss=3578.90478515625, ntokens=3926, nsentences=8, sample_size=3926
2022-07-12 17:24:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13101 / 16032 loss=3542.369384765625, ntokens=3933, nsentences=8, sample_size=3933
2022-07-12 17:24:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13201 / 16032 loss=3609.8671875, ntokens=3933, nsentences=8, sample_size=3933
2022-07-12 17:25:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13301 / 16032 loss=3583.023193359375, ntokens=3925, nsentences=8, sample_size=3925
2022-07-12 17:25:21 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13401 / 16032 loss=4155.40283203125, ntokens=3939, nsentences=8, sample_size=3939
2022-07-12 17:25:41 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13501 / 16032 loss=3765.20458984375, ntokens=3924, nsentences=8, sample_size=3924
2022-07-12 17:26:01 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13601 / 16032 loss=3876.65234375, ntokens=3936, nsentences=8, sample_size=3936
2022-07-12 17:26:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13701 / 16032 loss=3952.03515625, ntokens=3958, nsentences=8, sample_size=3958
2022-07-12 17:26:40 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13801 / 16032 loss=3471.242919921875, ntokens=3918, nsentences=8, sample_size=3918
2022-07-12 17:27:00 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  13901 / 16032 loss=3782.78076171875, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 17:27:20 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14001 / 16032 loss=3617.87548828125, ntokens=3919, nsentences=8, sample_size=3919
2022-07-12 17:27:39 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14101 / 16032 loss=3719.90576171875, ntokens=3945, nsentences=8, sample_size=3945
2022-07-12 17:27:59 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14201 / 16032 loss=3642.943115234375, ntokens=3945, nsentences=8, sample_size=3945
2022-07-12 17:28:19 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14301 / 16032 loss=3512.495361328125, ntokens=3938, nsentences=8, sample_size=3938
2022-07-12 17:28:38 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14401 / 16032 loss=4314.40869140625, ntokens=3942, nsentences=8, sample_size=3942
2022-07-12 17:28:58 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14501 / 16032 loss=3850.839599609375, ntokens=3938, nsentences=8, sample_size=3938
2022-07-12 17:29:17 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14601 / 16032 loss=3629.496826171875, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 17:29:37 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14701 / 16032 loss=3880.424560546875, ntokens=3952, nsentences=8, sample_size=3952
2022-07-12 17:29:56 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14801 / 16032 loss=3677.06494140625, ntokens=3960, nsentences=8, sample_size=3960
2022-07-12 17:30:16 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  14901 / 16032 loss=3892.615234375, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 17:30:35 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15001 / 16032 loss=3641.246337890625, ntokens=3930, nsentences=8, sample_size=3930
2022-07-12 17:30:54 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15101 / 16032 loss=3608.75732421875, ntokens=3942, nsentences=8, sample_size=3942
2022-07-12 17:31:14 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15201 / 16032 loss=3828.1728515625, ntokens=3962, nsentences=8, sample_size=3962
2022-07-12 17:31:33 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15301 / 16032 loss=3697.800048828125, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 17:31:52 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15401 / 16032 loss=3621.797119140625, ntokens=3958, nsentences=8, sample_size=3958
2022-07-12 17:32:12 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15501 / 16032 loss=3530.76708984375, ntokens=3960, nsentences=8, sample_size=3960
2022-07-12 17:32:31 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15601 / 16032 loss=3577.775634765625, ntokens=3964, nsentences=8, sample_size=3964
2022-07-12 17:32:51 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15701 / 16032 loss=3549.781005859375, ntokens=3979, nsentences=8, sample_size=3979
2022-07-12 17:33:10 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15801 / 16032 loss=3622.83544921875, ntokens=3957, nsentences=8, sample_size=3957
2022-07-12 17:33:29 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  15901 / 16032 loss=3416.10986328125, ntokens=3952, nsentences=8, sample_size=3952
2022-07-12 17:33:49 | INFO | fairseq.logging.progress_bar | valid on 'valid' subset:  16001 / 16032 loss=3671.572509765625, ntokens=3970, nsentences=8, sample_size=3970
2022-07-12 17:33:55 | INFO | valid | valid on 'valid' subset | loss 1.347 | ppl 2.54 | wps 0 | wpb 6.10422e+07 | bsz 128256
